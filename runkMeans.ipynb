{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分割聚类bi-kmeans\n",
    
    "## 主题概念（略）\n",
    "\n",
    "## 主要思想  \n",
    "\n",
    "单一过程来看原理：  关键词是 母簇 子簇  新簇  回到母簇，区分本簇（现有的簇）  \n",
    "   现有的母簇都有母子分支，从候选集（本簇也是母簇）中选拔误差平方和降低量最大的母簇做分裂，聚类个数增加1。  \n",
    "   母簇分裂得到两子簇，取代原来的母簇，正式成为新簇。  \n",
    "   聚类个数达到要求，则可以提交分裂结果。新簇内部还没有二分聚类，如果聚类个数不够，新簇如循环初始一样，继续二分聚类，成为新生的母簇。   \n",
    "   每次分裂的两个新簇各自二分聚类，生成两簇母子分支，新生的母簇加入到候选待分裂的母簇集中，继续开头所描述的过程。  \n",
    "   \n",
    "循环过程切入初始条件：      \n",
    "初始：单一簇整个为新簇    \n",
    "新生成的簇切入初始条件，内部二分割聚类，变成新生的母簇。初始的母簇是单一的。  \n",
    "——母簇概念的明确：具备母子分支，又不分裂，才能称之为母簇。    \n",
    "获取各母簇的母子分支的误差平方和降低量（在前一步新簇变为母簇时完成计算）    \n",
    "从多个（非单一）母簇中选降低量最大的那一个分裂    \n",
    "被分裂的母簇被内部已经二分割聚类生成的子簇（新生成的簇）替代，子簇变为新簇。    \n",
    "开始循环的第一步是新簇变母簇：  \n",
    "新簇内部二分割聚类，共得到两簇母子分支。  \n",
    "每次新的循环的标志事件是：  \n",
    "新进两簇母簇入选待分裂的母簇集，可以区分出每次循环的不同候选集和不同的分裂结果。  \n",
    "\n",
    "# 改进的二分聚类 选用的优化目标：母簇分裂的误差平方和降低量\n",
    "优化目标选择了母簇的母子分支的误差平方和降低量，而不是每个母簇分裂方案的总误差。\n",
    "类似决策树做分类的信息增益Gain，不同的是非监督方式，其实大道相通。\n",
    "簇内的误差平方和越小，样本相互越靠近，越纯洁，越容易划分到一类中来。\n",
    "误差平方和降低量越大，说明得到簇的过程（到达肘部elbow）越快，这一步迈得越大。\n",
    "SST=SSR+SSE   总离差平方和=簇间（组间）平方和（反映偏差）+簇内（组内）残差平方和（反映方差）\n",
    "取X=ε^即的误差ε的估计量,根据方差性质E(X^2)=E(X)^2+D(X)，可以得知系统偏差和方差的影响。\n",
    "这两个理论为选取误差平方和为聚类分析指标提供了尺度上的把握。\n",
    "极端情况下，单一簇，误差平方和最大，为总离差；\n",
    "         单样本簇，每个簇只有一个数据，误差平方和最小，为零。\n",
    "实际聚类情况，误差平方和达到应用要求的某一控制水平。\n",
    "误差平方和作为聚类的指示指标，是比较方便可行的。\n",
    "\n",
    "优化目标选择了母簇的母子分支的误差平方和降低量，而不是每个母簇分裂方案的总的误差平方和。这是为了程序选拔母簇有更加方便的针对指标，不需要关注总误差，只要具体到谁。\n",
    "\n",
    "母簇新生成时都通过二分聚类做了母子分支，并计算了母簇内的误差平方和降低量。\n",
    "此番改进不像标准的二分聚类程序，缺点是：\n",
    "每增加一个簇，要把各个母簇重复一次二分聚类，相当的重算一遍误差平方和降低量的工作量，而改进的程序仅对新生的母簇做二分聚类和误差统计。\n",
    "改进程序的存储空间保留了当前各本簇中心点、全体样本对各簇的从属关系、统计的本簇的误差项。\n",
    "增加了子簇中心点、各簇内样本对其各子簇的从属关系、子簇内的统计误差项。\n",
    "\n",
    "时空开销的权衡比较：\n",
    "空间最明显的增加就是子簇的从属关系，体量相当于全体样本对各簇的从属关系，增加了一倍的空间开销，但压缩了(K-2)的重复二分聚类和误差统计（最后一步K个聚类）的时间开销。\n",
    "\n",
    "改进的适用情况：\n",
    "   越多的聚类个数，越需要压缩重复二分聚类和误差统计的时间开销，尽管二分聚类每个母簇的样本数也在减小。改进的误差平方和降低量优化方法更加适合。\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "## 细节问题梳理（因果倒推，上因（准备+条件）下果，目标导向思维。）\n",
    "聚类细节上的因果关系清理\n",
    "单一的簇变成母簇                     生成母子分支，但未分裂\n",
    "\n",
    "初始到正常的母簇数量增长过程   \n",
    "                               单一母簇直接分裂  \n",
    "                               不用选择，就是她，没有选择的问题  \n",
    "\n",
    "正常的分裂过程针对多个非单一的母簇  \n",
    "                                   新生成的母簇，母簇之间确定  \n",
    "                                  谁是分裂者，数量至少是2个母簇。  \n",
    "\n",
    "\n",
    "                                   对分裂的母簇二分割聚类生成子簇    \n",
    "已有的各未分裂母子分支的误差平方和降低量      计算各母子分支的误差平方和降低量  \n",
    "\n",
    "\n",
    "已有的母子分支（子簇未分裂出去）            更新的母子分支（子簇分裂出去）  \n",
    "\n",
    "\n",
    "\n",
    "准备好各母子分支，误差平方和降低量  \n",
    "\n",
    " 从各母子分支中选拔误差平方和降低量最大的，聚类个数增加1，更新两子簇为母簇。  \n",
    " 聚类个数达到要求，停止聚类，不再分裂母簇。  \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化的kmeans数据字典\n",
    "\n",
    "术语概念空间：  \n",
    "簇概念空间的划分为两维：本，母，子，新生；中心坐标，所属关系，误差平方项  \n",
    "数据对象：列表、矩阵、数组；生命周期有初始化，使用，更新（生成）  \n",
    "数据对象是簇等术语概念的载体。  \n",
    "\n",
    "术语概念和关系需要根据程序设计来精化，不要搞大而全的覆盖。    \n",
    "同SQL关系数据库一样要做E-R范式依赖关系的分解。  \n",
    "为程序执行提供存储结构（安排一定的数据对象），也要为人的审查提供视图（连接查询）。  \n",
    "E-R分解体现程序设计的精简要义。不能把全连接作为存储和执行单元。  \n",
    "人机的设计和执行单元划分有所不同，人机各界：人的东西要聚合要包容，机的执行和存储要精当，组合连接要灵活，覆盖人的需求。  \n",
    "\n",
    "\n",
    "本簇：\n",
    "本簇（中心坐标，误差平方和SSE） CurrentClusters可分解的复合表\n",
    "currentCentroids表存放本簇中心点坐标√\n",
    "ClusterErrorSum表存放误差平方和SSE√\n",
    "clusterAssment簇所属表，存放所属的簇的中心号，到簇中心的距离平方 √\n",
    "全体样本与所属簇的从属关系：\n",
    "样本⁮点 → 簇中心    （所属簇的中心号，到簇中心的距离平方）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "母簇：本簇的扩展，程序中本簇的主要代表者，不另行命名\n",
    "母簇（Index：本簇中心号，子簇中心坐标,分裂后的残差，子簇划分带来的误差平方和降低量）\n",
    "其中，本簇中心号不用列出，直接排位区分，是索引。\n",
    "newCluster=[newClusterCentroids ID as Index->,subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "                             √      √          \n",
    "都可以分解独立成表\n",
    "最终只取subClusterCentroids,subClusterAss（可导出subClusterErrorSum和splitedError）\n",
    "subClusterErrorSum=[np.sum(clusterAss[clusterAss[:,0]==i, 1]) for i in [0,1]]\n",
    "\n",
    "母簇内两种从属关系：\n",
    "全体样本与所属母簇的从属关系：\n",
    "样本⁮点 → 母簇中心    （所属母簇的中心号，到母簇中心的距离平方）\n",
    "\n",
    "subclusterAss子簇所属表 √\n",
    "簇内样本与子簇的从属关系：\n",
    "本簇内：\n",
    "样本⁮点 → 子簇中心（所属子簇的中心号，到子簇中心的距离平方）\n",
    "\n",
    "#subClusterCentroids,splitedError,subClusterErrorSum,subClusterAss\n",
    "#=newCluster(ptsInCluster,k=2)#ptsInCluster为准母簇\n",
    "\n",
    "子簇：\n",
    "子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表\n",
    "subClusterCentroids表存放子簇中心点坐标√\n",
    "subClusterErrorSum表存放各子簇的误差平方和SSE√    身份只是中间表\n",
    "用于分裂后，转正为ClusterErrorSum表存放误差平方和SSE\n",
    "\n",
    "\n",
    "ErrorDelta表 子簇划分带来的误差平方和降低量，二分割新簇得到的新生母簇时生成，用于分裂母簇选拔。\n",
    "\n",
    "辅助的历史记录表   在母簇分裂时更新\n",
    "discenter表示被分裂的一代代母簇\n",
    "#存储有：  \n",
    "中心点，含有的误差平方和，\n",
    "母子分支的误差平方和的降低量，分裂后的残差平方和，初始和新生成时都空置，其更新在新簇二分割聚类生成母簇时进行。   \n",
    "就有了\n",
    "disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表  \n",
    "\n",
    "新生簇（初始条件和循环结束条件）newCluster：\n",
    "新生簇中心表 newClusterCentroids   新生簇的中心点坐标，新生的是两个子簇，故为2组坐标的列表。\n",
    "新生簇的所属表 newClusterAssment\n",
    "新生簇的误差平方和newClusterErrorSum \n",
    "新生簇在当前簇集中的序号Indexes_of_newClusterCentroids_In_currentCentroids\n",
    "新生簇没有ErrorDelta表，因为还没有分裂\n",
    "\n",
    "\n",
    "\n",
    "数据对象的生命周期：\n",
    "注意区分使用和生成（一般设空值）、初始化赋值（更新），以此为线索检查调试程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术小trick\n",
    "#按：注意：0,1两簇的编号如果直接按照needToSplit和len(currentCentroids) 更新\n",
    "        #因为newClusterAssment不能区分编号，会出现干扰。\n",
    "        #为保险起见，needToSplit先不做needToSplit更新，而是采用很大的数值\n",
    "        #大数值例如needToSplit+10000，替换该编号\n",
    "        #不出现混淆时，len(currentCentroids) 更新顺利完成后，needToSplit+10000改回needToSplit\n",
    "        \n",
    "#注意对空簇的处置   \n",
    "\n",
    "#按：重点细节 1号子簇要优先更新，以避免与0号子簇的needToSplit=1干扰情况出现：\n",
    "  0号子簇如果先更新，有可能更新的值needToSplit恰好是1，在1号子簇更新时没有保护，也被更新掉！\n",
    "#获得剩余数据集的误差\n",
    "nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])  \n",
    "                不是从dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]获取误差\n",
    "#newCentroids = centroids#.A  #错误源，不能带.A，这是两个子簇的族，源代码有.A （变为数组）\n",
    "\n",
    "#分组严重的不均衡现象的原因？needToSplit = j的限制  初始化 needToSplit = 0  #提出来\n",
    "#注意：[0]可以把数据从单元素列表中取出\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鸣谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yoyoyohamapi/mit-ml 斯坦福机器学习完整 python 实现  \n",
    "提供了原始学习素材，本篇参考了kmeans部分。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码正文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %load kmeans.py   加载共享的函数和库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load kmeans.py\n",
    "# kmeans.py\n",
    "import numpy as np\n",
    "\n",
    "def loadDataSet(filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    读取数据集\n",
    "\n",
    "    Args:\n",
    "        filename: 文件名\n",
    "    Returns:\n",
    "        dataMat: 数据样本矩阵\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 通过map函数批量转换\n",
    "        #fitLine = map(float, curLine)#py3中改为\n",
    "        fitLine =list(map(float, curLine))\n",
    "        dataMat.append(fitLine)\n",
    "    return dataMat\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    \"\"\"\n",
    "    计算两向量的欧氏距离\n",
    "\n",
    "    Args:\n",
    "        vecA: 向量A\n",
    "        vecB: 向量B\n",
    "    Returns:\n",
    "        欧式距离\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.power(vecA - vecB, 2)))\n",
    "\n",
    "def randCent(dataSet, k):\n",
    "    \"\"\"\n",
    "    随机生成k个聚类中心\n",
    "\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 簇数目\n",
    "    Returns:\n",
    "        centroids: 聚类中心矩阵\n",
    "    \"\"\"\n",
    "    _, n = dataSet.shape\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "    for j in range(n):\n",
    "        # 随机聚类中心落在数据集的边界之内\n",
    "        minJ = np.min(dataSet[:, j])\n",
    "        maxJ = np.max(dataSet[:, j])\n",
    "#         print('minJ =',minJ )\n",
    "        rangeJ = float(maxJ - minJ)\n",
    "        \n",
    "        centroids[:, j] = minJ + rangeJ * np.random.rand(k, 1)\n",
    "    return centroids\n",
    "\n",
    "def kMeans(dataSet, k, maxIter = 5):\n",
    "    \"\"\"\n",
    "    K-Means\n",
    "\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    # 随机初始化聚类中心\n",
    "    centroids = randCent(dataSet, k)\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))#按：开始，各子簇簇号都是0号\n",
    "    # 标识聚类中心是否仍在改变\n",
    "    clusterChanged = True\n",
    "    # 直至聚类中心不再变化\n",
    "    #按：补充，发现空簇\n",
    "    kong=k*[0]#各簇 计数，初始值0\n",
    "    iterCount = 0\n",
    "    while clusterChanged and iterCount < maxIter:\n",
    "        iterCount += 1\n",
    "        clusterChanged = False\n",
    "        # 分配样本到簇\n",
    "        for i in range(m):\n",
    "            # 计算第i个样本到各个聚类中心的距离\n",
    "            minIndex = 0\n",
    "            minDist = np.inf\n",
    "            for j in range(k):\n",
    "                dist = distEclud(dataSet[i, :],  centroids[j, :])\n",
    "                if(dist < minDist):\n",
    "                    minIndex = j\n",
    "                    minDist = dist\n",
    "            kong[minIndex]=kong[minIndex] +1       #各簇计数 \n",
    "            # 判断cluster是否改变\n",
    "            if(clusterAssment[i, 0] != minIndex):\n",
    "                clusterChanged = True\n",
    "            clusterAssment[i, :] = minIndex, minDist**2\n",
    "        \n",
    "        #判断是否有空簇  补充代码\n",
    "#         for j in range(k):\n",
    "#             if kong[j]==0:\n",
    "#                 print('出现第',j,'号空簇')\n",
    "        # 刷新聚类中心: 移动聚类中心到所在簇的均值位置\n",
    "        #空簇号kongids\n",
    "        kongids=[]\n",
    "        for cent in range(k):  #按：子簇在母簇内部编号cent\n",
    "            #过滤空簇   补充代码\n",
    "#             if kong[cent]==0:\n",
    "#                 print('出现第',j,'号空簇，现在跳过')\n",
    "#                 kongids.append(cent)#加入空簇号列表\n",
    "#                 continue\n",
    "            # 通过数组过滤获得簇中的点\n",
    "            ptsInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A == cent)[0]]  \n",
    "            #按：clusterAssment[:, 0].A变单列矩阵为数组A\n",
    "            if ptsInCluster.shape[0] > 0:\n",
    "                # 计算均值并移动     \n",
    "                #按：kMeans的由来 适用于数值型变量，本质是取序。\n",
    "                #因此，为避免极端值对均值的影响，kMeans不是不能用，而是要经过每维序号化预处理。\n",
    "                #序号化的中值设定为0，小端为负，大端为正。\n",
    "                centroids[cent, :] = np.mean(ptsInCluster, axis=0) #注： centroids是矩阵,本行可见\n",
    "    return centroids, clusterAssment#,kong,kongids #分别进行频率计数和空簇统计  \n",
    "def newCluster(ptsInCluster,k=2):#母簇ptsInCluster生成k=2分割的子簇,母簇号不用携带\n",
    "    #预备抽象的模块newCluster(ptsInCluster,k),\n",
    "    #返回newCluster=[newClusterCentroids,subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "    centroids, clusterAss = kMeans(ptsInCluster, k)\n",
    "    #按：此步为优化考虑点，不需要每次新增一簇就对全部的旧簇反复做二分聚类，仅仅针对新增的簇做二分聚类，并保存。\n",
    "    # 获得划分后的误差之和\n",
    "    \n",
    "    #不再承担老簇的统计，只需要统计本簇的新残差平方和\n",
    "#     m=len(ptsInCluster)\n",
    "#     centroid0 = np.mean(ptsInCluster, axis=0).tolist()[0]\n",
    "#     clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "#     for j in range(m):\n",
    "#         clusterAssment[j, 1] = distEclud(ptsInCluster[j, :], np.mat(centroid0))**2             \n",
    "#     oldClusterAssment=clusterAssment\n",
    "#     oldClusterErrorSum=np.sum(oldClusterAssment[:, 1])  \n",
    "            \n",
    "    splitedError= np.sum(clusterAss[:, 1])#新残差平方和\n",
    "#     ErrorDelta=oldClusterErrorSum-splitedError#不承担统计此功能\n",
    "#[[np.sum([a[i][1] for i in  range(len(a)) if a[i][0]==j])] for j in [0,1]] #可行的参考\n",
    "    subClusterErrorSum=[[np.sum([clusterAss[i,1] for i in  range(len(clusterAss)) \n",
    "                                 if clusterAss[i,0]==j])] for j in [0,1]]   \n",
    "    subClusterCentroids=centroids\n",
    "    subClusterAss=clusterAss\n",
    "\n",
    "    #以下两个等效动作是分裂动作，从子簇身份生成新簇，这是在选拔过程中完成的\n",
    "    #本过程是要确定母子分支，当好母簇。\n",
    "    #动作1\n",
    "#     newCluster0=[subClusterCentroids.tolist()[0],[],splitedError,ErrorDelta,subclusterAss]\n",
    "#     newCluster1=[subClusterCentroids.tolist()[1],[],splitedError,ErrorDelta,subclusterAss]\n",
    "#     newCluster=[newCluster0,newCluster1]\n",
    "    #动作2\n",
    "#     newCluster=[]\n",
    "#     for i in [0,1]:\n",
    "#         print(subClusterCentroids[i],'/n',i)        \n",
    "#         newCluster.append([subClusterCentroids[i],[],splitedError,ErrorDelta,subclusterAss[i]])\n",
    "#         #extend是对列表；append是对元素\n",
    "    #正确动作：返回母子分支，当好母簇\n",
    "#     newCluster=[[],subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "    #ErrorDelta不在放入了，改为subClusterErrorSum\n",
    "    newCluster=[subClusterCentroids,splitedError,subClusterErrorSum,subClusterAss]\n",
    "    print('type(subClusterCentroids)=',type(subClusterCentroids))\n",
    "    print('本身type(subClusterAss)=',type(subClusterAss))#矩阵\n",
    "                        #但在优化的。。。，下游，缺失#type of newClusterAssment= <class 'list'>\n",
    "    \n",
    "    return newCluster  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关注过程的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准的biKmeans    原load的py文件已改好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):     #ok的\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "        lowestError = np.inf\n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            centroids, clusterAss = kMeans(ptsInCurrCluster, 2)\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])\n",
    "            \n",
    "            print(\"splitedError, and nonSplitedError: \",splitedError,nonSplitedError)\n",
    "            # 比较，判断此次划分是否划算\n",
    "            if (splitedError + nonSplitedError) < lowestError:\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A    #按：0,1两族子簇\n",
    "#                 newCentroids = centroids#.A  #错误源，不是.A，源代码有.A\n",
    "                newClusterAss = clusterAss.copy()\n",
    "                # 如果划算，刷新总误差\n",
    "                lowestError = splitedError + nonSplitedError\n",
    "\n",
    "\n",
    "        # 更新簇的分配结果   \n",
    "        #按：重点细节 1号子簇要优先更新，以避免与needToSplit=1干扰：\n",
    "        #0号子簇如果先更新，有可能更新的值needToSplit恰好是1，在1号子簇更新时没有保护，也被更新掉！\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "\n",
    "        print( 'the bestCentToSplit -needToSplit is: ', needToSplit)\n",
    "        print ('the len of bestClustAss -newClusterAss is: ', len(newClusterAss))\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "    return np.mat(currentCentroids), clusterAssment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展一下biKmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):  #有小幅改动  运行ok！\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    #按：二分kmeans有不均衡聚类的倾向。\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    J=0\n",
    "    TotalError=[]\n",
    "    \n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "#         lowestError = np.inf\n",
    "        HighestError=0\n",
    "        TotalError.append(0)\n",
    "        Delta=[]#按：补充测试，存放DeltaErro\n",
    "        for j in range(len(currentCentroids)):\n",
    "             TotalError[J]+=clusterAssment[j, 1]\n",
    "                \n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "#             print('ptsInCluster:',ptsInCluster)#按：补充测试\n",
    "            print('len(ptsInCluster)',len(ptsInCluster))\n",
    "            ptsInClusterError = np.sum(ptsInCluster[:, 1])\n",
    "#             if len(ptsInCluster)==0:#空簇处置：新增代码 删除该中心，跳到下一for j循环\n",
    "#                 del(currentCentroids[j])\n",
    "#                 continue\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            \n",
    "            centroids, clusterAss = kMeans(ptsInCluster, 2)#按：权衡，时间和空间\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            DeltaError0=ptsInClusterError-splitedError\n",
    "            Delta.append(DeltaError0)\n",
    "            #求平均的误差降落\n",
    "            DeltaError= DeltaError0/(len(ptsInCluster)-1)\n",
    "            \n",
    "            #按：原文错误，下行做了替换\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "                        # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差  #按：替换的这一行\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])           \n",
    "                        \n",
    "            # 比较，判断此次划分是否划算\n",
    "#             if DeltaError/TotalError[J]<lowestError:\n",
    "#             if DeltaError<lowestError:\n",
    "            if DeltaError<HighestError:\n",
    "#                 lowestError=DeltaError/TotalError[J]\n",
    "#                 lowestError=DeltaError\n",
    "                HighestError=DeltaError\n",
    "#             if (splitedError + nonSplitedError) < lowestError:\n",
    "#                 # 如果划算，刷新总误差\n",
    "#                 lowestError = splitedError + nonSplitedError\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A  #错误源，不是.A，源代码有.A\n",
    "                newClusterAss = clusterAss.copy()#按：三个位置，搞不好就出错\n",
    "        # 更新簇的分配结果  #注意顺序，子簇1优先，不会串扰\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "#         print('currentCentroids=',currentCentroids)#按：补充测试\n",
    "        J+=1\n",
    "        print('第',J,'轮的len of newClusterAss=',len(newClusterAss))\n",
    "        print('取代第',needToSplit,'号母簇','0号子簇长度',len(newClusterAss[:, 0].A == 0))\n",
    "            #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "#     currentCentroids=np.vstack(currentCentroids)\n",
    "    print('Delta=',Delta)\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本人优化的biKmeans_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def biKmeans_(dataSet, k):   #按：改进二分聚类，不需要每次新增一簇就对全部的旧簇反复做二分聚类。\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    \n",
    "    #本簇的初始化，包括中心，所属，误差三项\n",
    "#     CurrentClusters=[]#初始化为分割前的当前的簇列表  #复合表，取消掉\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    " \n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "\t#循环初始化新簇，补充的代码\n",
    "    #新簇是为了二分支形成母簇而用\n",
    "\n",
    "    ClusterErrorSum=[[]]#此表存放误差平方和SSE  不能是[]\n",
    "    \n",
    "    \n",
    "    #子簇：\n",
    "    #子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表 ，未使用\n",
    "    #子簇的初始化，也包括中心，所属，误差三项   \n",
    "    subClusterCentroids=[[]]#子簇中心坐标表\n",
    "    subClusterAss=[[]]      #子簇所属表（所属子簇中心号，误差平方），可导出下列二项：\n",
    "    subClusterErrorSum=[[]]  #各子簇的误差平方和\n",
    "    splitedError=[[]]        #母簇分裂后的误差平方和，上述两子簇误差平方和相加\n",
    "    ErrorDelta=[[]]  #初始误差平方和降低量\n",
    "    #注：[[]]的初始值比[]有更多的灵活性，不是一直append，还可以杀回马枪从取空[]的a[i].append()添加元素\n",
    "\n",
    "\n",
    "\n",
    "    #新生簇的初始化，也包括中心，所属，误差三项 ，为了和循环衔接  \n",
    "    newClusterCentroids=currentCentroids \n",
    "    newClusterAssment=clusterAssment\n",
    "    newClusterErrorSum=np.sum(newClusterAssment[:, 1]) #新簇的误差平方和\n",
    "    Indexes_of_newClusterCentroids_In_currentCentroids=[0]#新生簇在当前簇集中的序号\n",
    "#     ClusterErrorSum.append(newClusterErrorSum)#错误，改为下面的\n",
    "    ClusterErrorSum[0].append(newClusterErrorSum)\n",
    "\n",
    "    \n",
    "#     辅助的历史记录表   在母簇分裂时更新\n",
    "#     discenter=[] #可能直接用不上，是复合表\n",
    "    #初值可取[newClusterCentroids,newClusterErrorSum]   \n",
    "    #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量，分裂后的残差平方和\n",
    "    #disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表\n",
    "    disCenterIDs=[]\n",
    "    disCentroids=[]\n",
    "    disErrorSum=[]\n",
    "    disErrorDelta=[]\n",
    "    dissplitedError=[]\n",
    "    \n",
    "    needToSplit = 0 #提出来   初始化\n",
    " \n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "    # 直到簇的数目达标\n",
    "#     if len(currentCentroids) < k:    #按：要<而不是≤，循环结束时就已经生成全部k个中心点，k-1+1=k个簇\n",
    "        # 当前最小的代价\n",
    "        highestErrorDelta = 0\n",
    "        # 对于每一个簇    #按：改为，对每一个新簇，存储二分聚类的两个子簇，还有误差平方和及其二分聚类的降低量。     \n",
    "    \n",
    "        for j in Indexes_of_newClusterCentroids_In_currentCentroids:\n",
    "            # 获得该簇的样本           \n",
    "#             ptsInCluster = dataSet[np.nonzero(newClusterAssment[:, 0].A == j)[0], :]\n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:,0].A == j)[0], :]\n",
    "            # 在该簇上进行2-means聚类\n",
    "            newClusterPre=newCluster(ptsInCluster,2)      \n",
    "            #返回subClusterCentroids,splitedError,subClusterErrorSum,subclusterAss\n",
    "            #                二立 ， 单立，           二立，         原样本混沌不分\n",
    "#             print('newClusterPre[3]=',newClusterPre[3])\n",
    "            print('type(newClusterPre[3])=',type(newClusterPre[3]))\n",
    "            #按：测试结果： type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
    "            subClusterCentroids[j].extend(newClusterPre[0])#更新j的[] ,这是二立情况\n",
    "            #按：要注意append和extend的区别！extend针对列表合并，append针对元素的追加\n",
    "            print('append的subClusterCentroids=',subClusterCentroids[j])\n",
    "            #append的subClusterCentroids= [[matrix([[-0.2897198 , -2.83942545]])]]\n",
    "            splitedError[j].append(newClusterPre[1])\n",
    "            subClusterErrorSum[j].append(newClusterPre[2])#这是二立情况\n",
    "#             subClusterAss[j].append(newClusterPre[3]) #按：[j]不可省掉，否则反复乱下去。重点细节\n",
    "            subClusterAss[j].append(newClusterPre[3]) #  不宜用extend，否则得到一行行materix碎片\n",
    "            print('ClusterErrorSum[',j,']=',ClusterErrorSum[j])#得 ClusterErrorSum[ 0 ]= [1465.5800234838164]\n",
    "            print('splitedError[',j,']=',splitedError[j]) #得 splitedError[ 0 ]= [828.6926539968681]\n",
    "            print('ClusterErrorSum[',j,'][0]=',ClusterErrorSum[j][0])#得 ClusterErrorSum[ 0 ]= [1465.5800234838164]\n",
    "            print('splitedError[',j,'][0]=',splitedError[j][0]) #得 splitedError[ 0 ]= [828.6926539968681]\n",
    "            ErrorDelta[j].append((ClusterErrorSum[j][0]-splitedError[j][0]))#这是单立情况\n",
    "            #注意：[0]可以把数据从单元素列表中取出\n",
    "            #             ErrorDelta[j].append([ClusterErrorSum[j]-splitedError[j]])#原始写法出错\n",
    "            #出错TypeError: unsupported operand type(s) for -: 'list' and 'list'\n",
    "\n",
    "        # 比较，判断此次划分是否划算\n",
    "#         currentClusters=np.mat(CurrentClusters) #当前的簇矩阵\n",
    "#             print('currentClusters[j,:]',currentClusters[j,:])\n",
    "        print('&&&&&&&&&&&&&&&&&&&&&&ErrorDelta&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&')\n",
    "        print(ErrorDelta)\n",
    "        for j in range(len(currentCentroids)):\t\n",
    "            #needToSplit = j #不应放在此处，会导致不均衡\n",
    "            if ErrorDelta[j][0] >highestErrorDelta :#& len(currentCentroids)>1:\n",
    "                #ErrorDelta[j] >....写法出错TypeError: '>' not supported between instances of 'list' and 'int'\n",
    "                #按：currentClusters[j,3]即ErrorDelta\n",
    "                # 如果还有更大降低量，刷新误差平方和的最大降低量\n",
    "                highestErrorDelta = ErrorDelta[j][0]\n",
    "                print('ErrorDelta[',j,'][0]=',ErrorDelta[j][0])\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果  #按：选拔要分裂的那个母簇\n",
    "        print('needToSplit=',needToSplit)\n",
    "#         print('subClusterAss[needToSplit]=',subClusterAss[needToSplit])\n",
    "#         newCentroids =currentCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列   错误，这是单簇了\n",
    "        newCentroids =subClusterCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列\n",
    "        print('newCentroids=',newCentroids)\n",
    "        print('type of newCentroids=',type(newCentroids))\n",
    "#         newClusterAssment =clusterAssment[needToSplit]#按：子簇所属子簇号0或1，距离子簇中心平方不用动\n",
    "        newClusterAssment =subClusterAss[needToSplit][0] #按：列表subClusterAss[needToSplit]取首元素，加[0]\n",
    "#         print('newClusterAssment=',newClusterAssment)\n",
    "        print('工作点 type of newClusterAssment=',type(newClusterAssment))\n",
    "        #按：newClusterAssment =subClusterAss[needToSplit]的\n",
    "        #测试结果为 type of newCentroids= <class 'list'>，后面的矩阵用法要加上[0]\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        #重点：找到错误根源所属关系矩阵或表，不能直接用needToSplit来给，它不是序号或行号，而是元素的首位数值\n",
    "        print('clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape=',\n",
    "              clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape)        \n",
    "#         print('待分裂的currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('len(currentCentroids)=',len(currentCentroids),'选第',needToSplit,'号母簇')\n",
    "        print('下面的0、1子簇，中心为：',newCentroids)\n",
    "        '''\n",
    "        '''\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 1)[\n",
    "            0], 0] =len(currentCentroids) \n",
    "        #TypeError: list indices must be integers or slices, not tuple \n",
    "        #出错源在newClusterAssment更新用了[[]]，而不是[]!\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 0)[  #按：np.nonzero()，()内非零的逻辑判断，取逻辑真。\n",
    "            0], 0]=needToSplit  \n",
    "        #保护0号子簇，前面1号子簇的序号len(currentCentroids)>0 ，不会冲突。 \n",
    "        #反过来，先更新0号子簇为needToSplit，如果needToSplit恰好为1，接下来更新1号子簇时，继续被更新。\n",
    "        \n",
    "        #len(np.nonzero(newClusterAssment[:, 0].A == 1)[0])*[len(currentCentroids)]\n",
    "        #按：len(currentCentroids) ?不对\n",
    "        #按：实际的簇号增加了，从len(currentCentroids)-1变为len(currentCentroids)\n",
    "        \n",
    "        #以下两行废弃，改为第三行\n",
    "        #newClusterErrorSum=[]\n",
    "        #newClusterErrorSum.extend(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        newClusterErrorSum=subClusterErrorSum[needToSplit][0]\n",
    "        #仿效 newClusterAssment =subClusterAss[needToSplit][0]，不用下面的\n",
    "#         newClusterErrorSum.append(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        print('newClusterErrorSum=',newClusterErrorSum,'for needToSplit=',needToSplit)\n",
    "        #测得newClusterErrorSum= [[[466.63278133614426], [326.28407520118242]]] for needToSplit= 0\n",
    "#         print('检查newClusterAssment种类',np.unique(newClusterAssment[:, 0].A))\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        #本簇更新：分裂的母簇更新为新簇：\n",
    "        #保存历史记录（中心号，中心点坐标，误差项）\n",
    "        #依次更新两子簇的：误差项，从属关系，中心点\n",
    "        \n",
    "        # 1/4        分裂的母簇更新之前保存历史记录\n",
    "                #         被选的母簇的分裂动作，善后安排\n",
    "        \n",
    "        disCenterIDs.append(needToSplit)\n",
    "        disCentroids.append(currentCentroids[needToSplit])\n",
    "        disErrorSum.append(ClusterErrorSum[needToSplit])\n",
    "        disErrorDelta.append(ErrorDelta[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        dissplitedError.append(splitedError[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        \n",
    "        #2/4 误差项更新   注意区分使用和生成（更新）\n",
    "        #检查，已做掉的：\n",
    "        #ErrorDelta（确定分裂母簇时使用）\n",
    "        #splitedError、subClusterErrorSum 各子簇的误差平方和  新簇二分支形成母簇时使用，生成则在母簇分裂时\n",
    "        print('newClusterErrorSum[0]=',newClusterErrorSum[0])#测得 newClusterErrorSum[0]= [32.601242864951153]\n",
    "        ClusterErrorSum[needToSplit]=newClusterErrorSum[0]\n",
    "        ClusterErrorSum.append(newClusterErrorSum[1])\n",
    "        \n",
    "        splitedError[needToSplit]=[]\n",
    "        splitedError.append([])\n",
    "        subClusterErrorSum[needToSplit]=[]\n",
    "        subClusterErrorSum.append([]) \n",
    "        ErrorDelta[needToSplit]=[]\n",
    "        ErrorDelta.append([]) \n",
    "        \n",
    "        #3/4 从属关系更新    包括本簇的和分裂的子簇的\n",
    "        #本簇的从属关系更新\n",
    "        # 刷新点分配结果    #按：所属簇号  即从属关系更新\n",
    "        print('$$$$$$$$$$$$$$$$$$$$$本簇的从属关系更新$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        print('len of clusterAssment: needToSplit=',len(clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :]))\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAssment  \n",
    "        print('np.unique(newClusterAssment[:, 0].A)=',np.unique(newClusterAssment[:, 0].A))\n",
    "        print('np.unique(clusterAssment[:, 0].A)=',np.unique(clusterAssment[:, 0].A ))\n",
    "        #按：原簇簇号为needToSplit的样本被新的二分簇族（注意：是族）\n",
    "        #                                             newClusterAss取代\n",
    "        #簇号不变  \n",
    "        #按：discenter表示被分裂的一代代母簇\n",
    "        #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量\n",
    "        #子簇的从属关系更新\n",
    "        subClusterAss[needToSplit]=[]#注意：不是[[]]\n",
    "        subClusterAss.extend([[]])\n",
    "        #4/4 中心点更新,包括本簇中心点更新currentCentroids和子簇中心点更新subClusterCentroids（重点：不能忽视）\n",
    "        #本簇中心点更新currentCentroids\n",
    "#         print('currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "         # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0]#.tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        print('newCentroids[1]=',newCentroids[1]) #按：newCentroids[1]是单坐标点的列表[[单坐标点]]\n",
    "        #newCentroids[1]= [[-3.38237045 -2.9473363 ]]  #返回一单行的矩阵[[]]  #重点关注，矩阵而非列表\n",
    "#         currentCentroids.extend(newCentroids[1])#.tolist()[0])#加了.tolist()[0] #按：注意append和extend差别\n",
    "        currentCentroids.append(newCentroids[1])#.tolist()[0]\n",
    "        print('currentCentroids[-1]',currentCentroids[-1])\n",
    "        print('currentCentroids[-1][0]',currentCentroids[-1][0])\n",
    "        #子簇中心点更新subClusterCentroids\n",
    "        subClusterCentroids[needToSplit]=[]\n",
    "#         subClusterCentroids.extend([])  #按：考察功底的时刻\n",
    "#         subClusterCentroids.extend([])    #按：等于什么也没干\n",
    "        subClusterCentroids.extend([[]])  #按：增加了空位，即插入了[]，该序号i是可以用[i]append()来补充元素的\n",
    "#         subClusterCentroids.append([[]])  #按：增加了元素[[]]，插入的是空元素的单元素表\n",
    "        print('subClusterCentroids=',subClusterCentroids)\n",
    "      \n",
    "  \n",
    "        #按：一对分裂的子簇变成一对新生簇，内部二分割变成待选分裂的母簇\n",
    "#         newClusterCentroids=[]\n",
    "#         newClusterCentroids.append(currentCentroids[needToSplit])\n",
    "#         newClusterCentroids.append(currentCentroids[-1])\n",
    "        Indexes_of_newClusterCentroids_In_currentCentroids=[needToSplit,len(currentCentroids)-1]\n",
    "        print('Indexes_of_newClusterCentroids_In_currentCentroids=',Indexes_of_newClusterCentroids_In_currentCentroids)    \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('#####################################################################################')\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "    #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "    currentCentroids=np.vstack(currentCentroids)\n",
    "#         currentCentroids\n",
    "    print('最终的ErrorDelta=',ErrorDelta)\n",
    "    print('最终的disErrorDelta=',disErrorDelta)\n",
    "        \n",
    "#     return np.mat(currentCentroids), clusterAssment\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主调main  ：作为测试口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 1.3368722 ,  1.16964922]])]\n",
      "ClusterErrorSum[ 0 ][0]= 1465.58002348\n",
      "splitedError[ 0 ][0]= 915.168062263\n",
      "newCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 1.3368722 ,  1.16964922]])]\n",
      "type of newCentroids= <class 'list'>\n",
      "工作点 type of newClusterAssment= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "len of newClusterAssment= 80\n",
      "clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape= (80, 2)\n",
      "currentCentroids= [[-0.10361321250000004, 0.05430119999999998]]\n",
      "len(currentCentroids)= 1 选第 0 号母簇\n",
      "下面的0、1子簇，中心为： [matrix([[-3.09539062, -2.26219085]]), matrix([[ 1.3368722 ,  1.16964922]])]\n",
      "newClusterErrorSum= [[152.23420024952998], [762.93386201393162]] for needToSplit= 0\n",
      "newClusterErrorSum[0]= [152.23420024952998]\n",
      "np.unique(newClusterAssment[:, 0].A)= [ 0.  1.]\n",
      "np.unique(clusterAssment[:, 0].A)= [ 0.  1.]\n",
      "newCentroids[1]= [[ 1.3368722   1.16964922]]\n",
      "currentCentroids[-1] [[ 1.3368722   1.16964922]]\n",
      "currentCentroids[-1][0] [[ 1.3368722   1.16964922]]\n",
      "subClusterCentroids= [[], []]\n",
      "Indexes_of_newClusterCentroids_In_currentCentroids= [0, 1]\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 1.3368722 ,  1.16964922]])]\n",
      "#####################################################################################\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-3.01169468, -3.01238673]])]\n",
      "ClusterErrorSum[ 0 ][0]= 152.23420025\n",
      "splitedError[ 0 ][0]= 70.0727880998\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[ 0.38075386,  3.12396831]]), matrix([[ 3.09814284, -2.43041226]])]\n",
      "ClusterErrorSum[ 1 ][0]= 762.933862014\n",
      "splitedError[ 1 ][0]= 291.700262441\n",
      "newCentroids= [matrix([[ 0.38075386,  3.12396831]]), matrix([[ 3.09814284, -2.43041226]])]\n",
      "type of newCentroids= <class 'list'>\n",
      "工作点 type of newClusterAssment= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "len of newClusterAssment= 54\n",
      "clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape= (54, 2)\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 1.3368722 ,  1.16964922]])]\n",
      "len(currentCentroids)= 2 选第 1 号母簇\n",
      "下面的0、1子簇，中心为： [matrix([[ 0.38075386,  3.12396831]]), matrix([[ 3.09814284, -2.43041226]])]\n",
      "newClusterErrorSum= [[238.26638927888183], [53.433873162422209]] for needToSplit= 1\n",
      "newClusterErrorSum[0]= [238.26638927888183]\n",
      "np.unique(newClusterAssment[:, 0].A)= [ 1.  2.]\n",
      "np.unique(clusterAssment[:, 0].A)= [ 0.  1.  2.]\n",
      "newCentroids[1]= [[ 3.09814284 -2.43041226]]\n",
      "currentCentroids[-1] [[ 3.09814284 -2.43041226]]\n",
      "currentCentroids[-1][0] [[ 3.09814284 -2.43041226]]\n",
      "subClusterCentroids= [[matrix([[-3.55571825,  1.8638865 ]]), matrix([[-3.01169468, -3.01238673]])], [], []]\n",
      "Indexes_of_newClusterCentroids_In_currentCentroids= [1, 2]\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 0.38075386,  3.12396831]]), matrix([[ 3.09814284, -2.43041226]])]\n",
      "#####################################################################################\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-2.18799937,  3.01824781]]), matrix([[ 2.54391447,  3.21299611]])]\n",
      "ClusterErrorSum[ 1 ][0]= 238.266389279\n",
      "splitedError[ 1 ][0]= 43.4550631947\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[ 3.23113972, -2.53879733]]), matrix([[ 0.704199, -0.479481]])]\n",
      "ClusterErrorSum[ 2 ][0]= 53.4338731624\n",
      "splitedError[ 2 ][0]= 43.3669343657\n",
      "newCentroids= [matrix([[-2.18799937,  3.01824781]]), matrix([[ 2.54391447,  3.21299611]])]\n",
      "type of newCentroids= <class 'list'>\n",
      "工作点 type of newClusterAssment= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "len of newClusterAssment= 35\n",
      "clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape= (35, 2)\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[ 0.38075386,  3.12396831]]), matrix([[ 3.09814284, -2.43041226]])]\n",
      "len(currentCentroids)= 3 选第 1 号母簇\n",
      "下面的0、1子簇，中心为： [matrix([[-2.18799937,  3.01824781]]), matrix([[ 2.54391447,  3.21299611]])]\n",
      "newClusterErrorSum= [[13.865285567632188], [29.589777627058528]] for needToSplit= 1\n",
      "newClusterErrorSum[0]= [13.865285567632188]\n",
      "np.unique(newClusterAssment[:, 0].A)= [ 1.  3.]\n",
      "np.unique(clusterAssment[:, 0].A)= [ 0.  1.  2.  3.]\n",
      "newCentroids[1]= [[ 2.54391447  3.21299611]]\n",
      "currentCentroids[-1] [[ 2.54391447  3.21299611]]\n",
      "currentCentroids[-1][0] [[ 2.54391447  3.21299611]]\n",
      "subClusterCentroids= [[matrix([[-3.55571825,  1.8638865 ]]), matrix([[-3.01169468, -3.01238673]])], [], [matrix([[ 3.23113972, -2.53879733]]), matrix([[ 0.704199, -0.479481]])], []]\n",
      "Indexes_of_newClusterCentroids_In_currentCentroids= [1, 3]\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[-2.18799937,  3.01824781]]), matrix([[ 3.09814284, -2.43041226]]), matrix([[ 2.54391447,  3.21299611]])]\n",
      "#####################################################################################\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-1.595569  ,  3.01158056]]), matrix([[-2.94969557,  3.02682   ]])]\n",
      "ClusterErrorSum[ 1 ][0]= 13.8652855676\n",
      "splitedError[ 1 ][0]= 6.64433970743\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[ 1.9686787,  3.5499161]]), matrix([[ 3.18306533,  2.83864056]])]\n",
      "ClusterErrorSum[ 3 ][0]= 29.5897776271\n",
      "splitedError[ 3 ][0]= 20.2077617544\n",
      "newCentroids= [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-3.01169468, -3.01238673]])]\n",
      "type of newCentroids= <class 'list'>\n",
      "工作点 type of newClusterAssment= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "len of newClusterAssment= 26\n",
      "clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape= (26, 2)\n",
      "currentCentroids= [matrix([[-3.09539062, -2.26219085]]), matrix([[-2.18799937,  3.01824781]]), matrix([[ 3.09814284, -2.43041226]]), matrix([[ 2.54391447,  3.21299611]])]\n",
      "len(currentCentroids)= 4 选第 0 号母簇\n",
      "下面的0、1子簇，中心为： [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-3.01169468, -3.01238673]])]\n",
      "newClusterErrorSum= [[5.932807719301751], [64.139980380541132]] for needToSplit= 0\n",
      "newClusterErrorSum[0]= [5.932807719301751]\n",
      "np.unique(newClusterAssment[:, 0].A)= [ 0.  4.]\n",
      "np.unique(clusterAssment[:, 0].A)= [ 0.  1.  2.  3.  4.]\n",
      "newCentroids[1]= [[-3.01169468 -3.01238673]]\n",
      "currentCentroids[-1] [[-3.01169468 -3.01238673]]\n",
      "currentCentroids[-1][0] [[-3.01169468 -3.01238673]]\n",
      "subClusterCentroids= [[], [matrix([[-1.595569  ,  3.01158056]]), matrix([[-2.94969557,  3.02682   ]])], [matrix([[ 3.23113972, -2.53879733]]), matrix([[ 0.704199, -0.479481]])], [matrix([[ 1.9686787,  3.5499161]]), matrix([[ 3.18306533,  2.83864056]])], []]\n",
      "Indexes_of_newClusterCentroids_In_currentCentroids= [0, 4]\n",
      "currentCentroids= [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-2.18799937,  3.01824781]]), matrix([[ 3.09814284, -2.43041226]]), matrix([[ 2.54391447,  3.21299611]]), matrix([[-3.01169468, -3.01238673]])]\n",
      "#####################################################################################\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-3.14546667,  1.36566633]]), matrix([[-4.786473,  3.358547]])]\n",
      "ClusterErrorSum[ 0 ][0]= 5.9328077193\n",
      "splitedError[ 0 ][0]= 0.934451366091\n",
      "type(subClusterCentroids)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "本身type(subClusterAss)= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "append的subClusterCentroids= [matrix([[-0.28093075, -3.880518  ]]), matrix([[-3.61853111, -2.81946867]])]\n",
      "ClusterErrorSum[ 4 ][0]= 64.1399803805\n",
      "splitedError[ 4 ][0]= 23.9986652081\n",
      "newCentroids= [matrix([[-0.28093075, -3.880518  ]]), matrix([[-3.61853111, -2.81946867]])]\n",
      "type of newCentroids= <class 'list'>\n",
      "工作点 type of newClusterAssment= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "len of newClusterAssment= 22\n",
      "clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape= (22, 2)\n",
      "currentCentroids= [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-2.18799937,  3.01824781]]), matrix([[ 3.09814284, -2.43041226]]), matrix([[ 2.54391447,  3.21299611]]), matrix([[-3.01169468, -3.01238673]])]\n",
      "len(currentCentroids)= 5 选第 4 号母簇\n",
      "下面的0、1子簇，中心为： [matrix([[-0.28093075, -3.880518  ]]), matrix([[-3.61853111, -2.81946867]])]\n",
      "newClusterErrorSum= [[5.9104381869447504], [18.088227021121781]] for needToSplit= 4\n",
      "newClusterErrorSum[0]= [5.9104381869447504]\n",
      "np.unique(newClusterAssment[:, 0].A)= [ 4.  5.]\n",
      "np.unique(clusterAssment[:, 0].A)= [ 0.  1.  2.  3.  4.  5.]\n",
      "newCentroids[1]= [[-3.61853111 -2.81946867]]\n",
      "currentCentroids[-1] [[-3.61853111 -2.81946867]]\n",
      "currentCentroids[-1][0] [[-3.61853111 -2.81946867]]\n",
      "subClusterCentroids= [[matrix([[-3.14546667,  1.36566633]]), matrix([[-4.786473,  3.358547]])], [matrix([[-1.595569  ,  3.01158056]]), matrix([[-2.94969557,  3.02682   ]])], [matrix([[ 3.23113972, -2.53879733]]), matrix([[ 0.704199, -0.479481]])], [matrix([[ 1.9686787,  3.5499161]]), matrix([[ 3.18306533,  2.83864056]])], [], []]\n",
      "Indexes_of_newClusterCentroids_In_currentCentroids= [4, 5]\n",
      "currentCentroids= [matrix([[-3.55571825,  1.8638865 ]]), matrix([[-2.18799937,  3.01824781]]), matrix([[ 3.09814284, -2.43041226]]), matrix([[ 2.54391447,  3.21299611]]), matrix([[-0.28093075, -3.880518  ]]), matrix([[-3.61853111, -2.81946867]])]\n",
      "#####################################################################################\n",
      "运行时间 0.29599881172180176\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ccdb23b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load test_normal_kmeans.py\n",
    "#test_normal_kmeans.py\n",
    "import time as tm\n",
    "import kmeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#按：在Notepad++中运行python脚本 cmd /k D:\\ProgramData\\Anaconda2\\envs\\py3\\python.exe \"$(FULL_CURRENT_PATH)\" & PAUSE & EXIT\n",
    "if __name__ == \"__main__\":\n",
    "    s=tm.time()\n",
    "    dataMat = np.mat(loadDataSet('data/testSet.txt'))#kmeans.\n",
    "#     centroids, clusterAssment = kMeans(dataMat,6) \n",
    "    #6运行时间 0.2850019931793213\n",
    "    #kmeans.2运行时间  0.09799885749816895\n",
    "#     centroids, clusterAssment = biKmeans(dataMat, 6)\n",
    "    #6 运行时间 0.3880009651184082 #注意对空簇的处置      \n",
    "    #2运行时间 0.13300228118896484\n",
    "    centroids, clusterAssment = biKmeans_(dataMat,6)  \n",
    "    #6运行时间 0.28999781608581543  \n",
    "    #2运行时间 0.3789994716644287\n",
    "    clusterCount = np.shape(centroids)[0]\n",
    "    m = np.shape(dataMat)[0]\n",
    "    print('运行时间',tm.time()-s)\n",
    "    # 绘制散点图\n",
    "    patterns = ['o', 'D', '^', 's','*','P','H','x']   #discent消失的中心备用'v'倒三角\n",
    "    colors = ['b', 'g', 'y', 'black','c','r','m','w']\n",
    "    #补充：颜色参数：\n",
    "#b--blue    c--cyan    g--green  k--black\n",
    "#m--magenta r--red     w--white  y--yellow\n",
    "    fig = plt.figure()\n",
    "    title = 'kmeans with k='+str(clusterCount)\n",
    "    ax = fig.add_subplot(111, title=title)\n",
    "    for k in range(clusterCount):\n",
    "        # 绘制聚类中心    #color='r修改，以便辨认\n",
    "        #空簇处理放在biKmeans等中\n",
    "        ax.scatter(centroids[k, 0], centroids[k, 1], color=str(colors[k]), marker='+', linewidth=20)\n",
    "        for i in range(m):\n",
    "            # 绘制属于该聚类中心的样本\n",
    "            ptsInCluster = dataMat[np.nonzero(clusterAssment[:, 0].A==k)[0]]\n",
    "            ax.scatter(ptsInCluster[:, 0].flatten().A[0], ptsInCluster[:, 1].flatten().A[0], marker=patterns[k], color=colors[k])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 汇总各种方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 专门biKmeans代码      ok的！\n",
    "https://www.cnblogs.com/MrLJC/p/4129700.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k, distMeas=distEclud):\n",
    "    #def distEclud(vecA, vecB):\n",
    "    m =np.shape(dataSet)[0]\n",
    "    clusterAssment =np.mat(np.zeros((m,2)))#记录簇分配的结果及误差\n",
    "    centroid0 =np.mean(dataSet, axis=0).tolist()[0]#计算整个数据集的质心\n",
    "    centList =[centroid0] #create a list with one centroid\n",
    "    for j in range(m):#计算初始聚类点与其他点的距离\n",
    "        clusterAssment[j,1] = distMeas(np.mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k):\n",
    "        lowestSSE = np.inf\n",
    "        for i in range(len(centList)):#尝试划分每一簇\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:]#get the data points currently in cluster i\n",
    "#             ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)            \n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2)#后面参数, distMeas)#对这个簇运行一个KMeans算法，k=2\n",
    "            sseSplit = sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            sseNotSplit = sum(clusterAssment[np.nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print(\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:##划分后更好的话\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) #更新簇的分配结果change 1 to 3,4, or whatever\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit\n",
    "        print( 'the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print ('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[np.nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return np.mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准biKmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):     #ok的\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "        lowestError = np.inf\n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            centroids, clusterAss = kMeans(ptsInCurrCluster, 2)\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])\n",
    "            \n",
    "            print(\"splitedError, and nonSplitedError: \",splitedError,nonSplitedError)\n",
    "            # 比较，判断此次划分是否划算\n",
    "            if (splitedError + nonSplitedError) < lowestError:\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A\n",
    "                newClusterAss = clusterAss.copy()\n",
    "                # 如果划算，刷新总误差\n",
    "                lowestError = splitedError + nonSplitedError\n",
    "\n",
    "\n",
    "        # 更新簇的分配结果\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "        print( 'the bestCentToSplit -needToSplit is: ', needToSplit)\n",
    "        print ('the len of bestClustAss -newClusterAss is: ', len(newClusterAss))\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出的改进二分聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans_(dataSet, k):   #按：改进二分聚类，不需要每次新增一簇就对全部的旧簇反复做二分聚类。\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置    \n",
    "    #本簇的初始化，包括中心，所属，误差三项\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离 \n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "\t#循环初始化新簇，补充的代码\n",
    "    #新簇是为了二分支形成母簇而用\n",
    "    \n",
    "    ClusterErrorSum=[[]]#此表存放误差平方和SSE  不能是[]\n",
    "    #子簇：\n",
    "    #子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表 ，未使用\n",
    "    #子簇的初始化，也包括中心，所属，误差三项   \n",
    "    subClusterCentroids=[[]]#子簇中心坐标表\n",
    "    subClusterAss=[[]]      #子簇所属表（所属子簇中心号，误差平方），可导出下列二项：\n",
    "    subClusterErrorSum=[[]]  #各子簇的误差平方和\n",
    "    splitedError=[[]]        #母簇分裂后的误差平方和，上述两子簇误差平方和相加\n",
    "    ErrorDelta=[[]]  #初始误差平方和降低量\n",
    "\n",
    "    #新生簇的初始化，也包括中心，所属，误差三项 ，为了和循环衔接  \n",
    "    newClusterCentroids=currentCentroids \n",
    "    newClusterAssment=clusterAssment\n",
    "    newClusterErrorSum=np.sum(newClusterAssment[:, 1]) #新簇的误差平方和\n",
    "    Indexes_of_newClusterCentroids_In_currentCentroids=[0]#新生簇在当前簇集中的序号\n",
    "#     ClusterErrorSum.append(newClusterErrorSum)#错误，改为下面的\n",
    "    ClusterErrorSum[0].append(newClusterErrorSum)\n",
    "    \n",
    "#     辅助的历史记录表   在母簇分裂时更新\n",
    "#     discenter=[] #可能直接用不上，是复合表\n",
    "    #初值可取[newClusterCentroids,newClusterErrorSum]   \n",
    "    #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量，分裂后的残差平方和\n",
    "    #disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表\n",
    "    disCenterIDs=[]\n",
    "    disCentroids=[]\n",
    "    disErrorSum=[]\n",
    "    disErrorDelta=[]\n",
    "    dissplitedError=[]\n",
    "    \n",
    "    needToSplit = 0  #提出来\n",
    " \n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "    # 直到簇的数目达标\n",
    "#     if len(currentCentroids) < k:    #按：要<而不是≤，循环结束时就已经生成全部k个中心点，k-1+1=k个簇\n",
    "        # 当前最小的代价\n",
    "        highestErrorDelta = 0\n",
    "        # 对于每一个簇    #按：改为，对每一个新簇，存储二分聚类的两个子簇，还有误差平方和及其二分聚类的降低量。    \n",
    "    \n",
    "        for j in Indexes_of_newClusterCentroids_In_currentCentroids:\n",
    "            # 获得该簇的样本           \n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:,0].A == j)[0], :]\n",
    "            # 在该簇上进行2-means聚类\n",
    "            newClusterPre=newCluster(ptsInCluster,2)      \n",
    "            #返回subClusterCentroids,splitedError,subClusterErrorSum,subclusterAss\n",
    "            print('type(newClusterPre[3])=',type(newClusterPre[3]))\n",
    "            #按：测试结果： type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
    "            subClusterCentroids[j].extend(newClusterPre[0])#更新j的[] \n",
    "            #按：要注意append和extend的区别！extend针对列表合并，append针对元素的追加\n",
    "            print('append的subClusterCentroids=',subClusterCentroids[j])\n",
    "            #append的subClusterCentroids= [[matrix([[-0.2897198 , -2.83942545]])]]\n",
    "            splitedError[j].append(newClusterPre[1])\n",
    "            subClusterErrorSum[j].append(newClusterPre[2])\n",
    "#             subClusterAss[j].append(newClusterPre[3]) #按：[j]不可省掉，否则反复乱下去。重点细节\n",
    "            subClusterAss[j].append(newClusterPre[3]) #  不宜用extend，否则得到一行行materix碎片\n",
    "            print('ClusterErrorSum[',j,'][0]=',ClusterErrorSum[j][0])\n",
    "            print('splitedError[',j,'][0]=',splitedError[j][0]) \n",
    "            ErrorDelta[j].append((ClusterErrorSum[j][0]-splitedError[j][0]))\n",
    "\n",
    "        # 比较，判断此次划分是否划算\n",
    "        for j in range(len(currentCentroids)):\t\n",
    "#             needToSplit = j#不能放在此处，否则大块的簇分割不掉！\n",
    "            if ErrorDelta[j][0] >highestErrorDelta:# & len(currentCentroids)>1:\n",
    "                # 如果还有更大降低量，刷新误差平方和的最大降低量\n",
    "                highestErrorDelta = ErrorDelta[j][0]\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果  #按：选拔要分裂的那个母簇\n",
    "#         newCentroids =currentCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列   错误，这是单簇了\n",
    "        newCentroids =subClusterCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列\n",
    "        print('newCentroids=',newCentroids)\n",
    "        print('type of newCentroids=',type(newCentroids))\n",
    "        newClusterAssment =subClusterAss[needToSplit][0] \n",
    "#         print('newClusterAssment=',newClusterAssment)\n",
    "        print('工作点 type of newClusterAssment=',type(newClusterAssment))\n",
    "        #按：newClusterAssment =subClusterAss[needToSplit]的\n",
    "        #测试结果为 type of newCentroids= <class 'list'>，后面的矩阵用法要加上[0]\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        #重点：找到错误根源所属关系矩阵或表，不能直接用needToSplit来给，它不是序号或行号，而是元素的首位数值\n",
    "        print('clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape=',\n",
    "              clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape)        \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('len(currentCentroids)=',len(currentCentroids),'选第',needToSplit,'号母簇')\n",
    "        print('下面的0、1子簇，中心为：',newCentroids)\n",
    "        '''\n",
    "        '''\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 1)[\n",
    "            0], 0] =len(currentCentroids) #TypeError: list indices must be integers or slices, not tuple\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 0)[  #按：np.nonzero()，()内非零的逻辑判断，取逻辑真。\n",
    "            0], 0]=needToSplit  \n",
    "\n",
    "        #以下两行废弃，改为第三行\n",
    "        #newClusterErrorSum=[]\n",
    "        #newClusterErrorSum.extend(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        newClusterErrorSum=subClusterErrorSum[needToSplit][0]\n",
    "        #仿效 newClusterAssment =subClusterAss[needToSplit][0]，不用下面的\n",
    "#         newClusterErrorSum.append(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        print('newClusterErrorSum=',newClusterErrorSum,'for needToSplit=',needToSplit)\n",
    "        #测得newClusterErrorSum= [[[466.63278133614426], [326.28407520118242]]] for needToSplit= 0\n",
    "\n",
    "        \n",
    "        #本簇更新：分裂的母簇更新为新簇：\n",
    "        #保存历史记录（中心号，中心点坐标，误差项）\n",
    "        #依次更新两子簇的：误差项，从属关系，中心点\n",
    "        \n",
    "        # 1/4        分裂的母簇更新之前保存历史记录      \n",
    "        disCenterIDs.append(needToSplit)\n",
    "        disCentroids.append(currentCentroids[needToSplit])\n",
    "        disErrorSum.append(ClusterErrorSum[needToSplit])\n",
    "        disErrorDelta.append(ErrorDelta[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        dissplitedError.append(splitedError[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        \n",
    "        #2/4 误差项更新   注意区分使用和生成（更新）\n",
    "        #检查，已做掉的：\n",
    "        #ErrorDelta（确定分裂母簇时使用）\n",
    "        #splitedError、subClusterErrorSum 各子簇的误差平方和  新簇二分支形成母簇时使用，生成则在母簇分裂时\n",
    "        print('newClusterErrorSum[0]=',newClusterErrorSum[0])#测得 newClusterErrorSum[0]= [32.601242864951153]\n",
    "        ClusterErrorSum[needToSplit]=newClusterErrorSum[0]\n",
    "        ClusterErrorSum.append(newClusterErrorSum[1])        \n",
    "        #以下的要加上\n",
    "        splitedError[needToSplit]=[]\n",
    "        splitedError.append([])\n",
    "        subClusterErrorSum[needToSplit]=[]\n",
    "        subClusterErrorSum.append([]) \n",
    "        ErrorDelta[needToSplit]=[]\n",
    "        ErrorDelta.append([]) \n",
    "        \n",
    "        \n",
    "        \n",
    "        #3/4 从属关系更新    包括本簇的和分裂的子簇的\n",
    "        #本簇的从属关系更新\n",
    "        # 刷新点分配结果    #按：所属簇号  即从属关系更新\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAssment  \n",
    "        print('np.unique(newClusterAssment[:, 0].A)=',np.unique(newClusterAssment[:, 0].A))\n",
    "        print('np.unique(clusterAssment[:, 0].A)=',np.unique(clusterAssment[:, 0].A ))\n",
    "        #按：原簇簇号为needToSplit的样本被新的二分簇族（注意：是族）\n",
    "        #                                             newClusterAss取代\n",
    "        #簇号不变  \n",
    "        #按：discenter表示被分裂的一代代母簇\n",
    "        #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量\n",
    "        #子簇的从属关系更新\n",
    "        subClusterAss[needToSplit]=[]  #不能是[[]]，否则出错\n",
    "        subClusterAss.extend([[]])\n",
    "        \n",
    "        #4/4 中心点更新,包括本簇中心点更新currentCentroids和子簇中心点更新subClusterCentroids（重点：不能忽视）\n",
    "        #本簇中心点更新currentCentroids\n",
    "#         print('currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "         # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0]#.tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        print('newCentroids[1]=',newCentroids[1]) #按：newCentroids[1]是单坐标点的列表[[单坐标点]]\n",
    "        #newCentroids[1]= [[-3.38237045 -2.9473363 ]]  #返回一单行的矩阵[[]]  #重点关注，矩阵而非列表\n",
    "#         currentCentroids.extend(newCentroids[1])#.tolist()[0])#加了.tolist()[0] #按：注意append和extend差别\n",
    "        currentCentroids.append(newCentroids[1])#.tolist()[0]\n",
    "        print('currentCentroids[-1]',currentCentroids[-1])\n",
    "        print('currentCentroids[-1][0]',currentCentroids[-1][0])\n",
    "        #子簇中心点更新subClusterCentroids\n",
    "        subClusterCentroids[needToSplit]=[]\n",
    "#         subClusterCentroids.extend([])  #按：考察功底的时刻\n",
    "#         subClusterCentroids.extend([])    #按：等于什么也没干\n",
    "        subClusterCentroids.extend([[]])  #按：增加了空位，即插入了[]，该序号i是可以用[i]append()来补充元素的\n",
    "#         subClusterCentroids.append([[]])  #按：增加了元素[[]]，插入的是空元素的单元素表\n",
    "        print('subClusterCentroids=',subClusterCentroids)\n",
    "      \n",
    "  \n",
    "        #按：一对分裂的子簇变成一对新生簇，内部二分割变成待选分裂的母簇\n",
    "        Indexes_of_newClusterCentroids_In_currentCentroids=[needToSplit,len(currentCentroids)-1]\n",
    "        print('Indexes_of_newClusterCentroids_In_currentCentroids=',Indexes_of_newClusterCentroids_In_currentCentroids)    \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('#####################################################################################')\n",
    "\n",
    "    #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "    currentCentroids=np.vstack(currentCentroids)\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "475px",
    "left": "0px",
    "right": "auto",
    "top": "105px",
    "width": "301px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
