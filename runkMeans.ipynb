{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分割聚类bi-kmeans\n",
    "2018.07.22:22时-2018.07.26:04时\n",
    "## 主题概念（略）\n",
    "\n",
    "## 主要思想  \n",
    "\n",
    "单一过程来看原理：  关键词是 母簇 子簇  新簇  回到母簇，区分本簇（现有的簇）  \n",
    "   现有的母簇都有母子分支，从候选集（本簇也是母簇）中选拔误差平方和降低量最大的母簇做分裂，聚类个数增加1。  \n",
    "   母簇分裂得到两子簇，取代原来的母簇，正式成为新簇。  \n",
    "   聚类个数达到要求，则可以提交分裂结果。新簇内部还没有二分聚类，如果聚类个数不够，新簇如循环初始一样，继续二分聚类，成为新生的母簇。   \n",
    "   每次分裂的两个新簇各自二分聚类，生成两簇母子分支，新生的母簇加入到候选待分裂的母簇集中，继续开头所描述的过程。  \n",
    "   \n",
    "循环过程切入初始条件：      \n",
    "初始：单一簇整个为新簇    \n",
    "新生成的簇切入初始条件，内部二分割聚类，变成新生的母簇。初始的母簇是单一的。  \n",
    "——母簇概念的明确：具备母子分支，又不分裂，才能称之为母簇。    \n",
    "获取各母簇的母子分支的误差平方和降低量（在前一步新簇变为母簇时完成计算）    \n",
    "从多个（非单一）母簇中选降低量最大的那一个分裂    \n",
    "被分裂的母簇被内部已经二分割聚类生成的子簇（新生成的簇）替代，子簇变为新簇。    \n",
    "开始循环的第一步是新簇变母簇：  \n",
    "新簇内部二分割聚类，共得到两簇母子分支。  \n",
    "每次新的循环的标志事件是：  \n",
    "新进两簇母簇入选待分裂的母簇集，可以区分出每次循环的不同候选集和不同的分裂结果。  \n",
    "\n",
    "# 改进的二分聚类 选用的优化目标：母簇分裂的误差平方和降低量\n",
    "优化目标选择了母簇的母子分支的误差平方和降低量，而不是每个母簇分裂方案的总误差。\n",
    "类似决策树做分类的信息增益Gain，不同的是非监督方式，其实大道相通。\n",
    "簇内的误差平方和越小，样本相互越靠近，越纯洁，越容易划分到一类中来。\n",
    "误差平方和降低量越大，说明得到簇的过程（到达肘部elbow）越快，这一步迈得越大。\n",
    "SST=SSR+SSE   总离差平方和=簇间（组间）平方和（反映偏差）+簇内（组内）残差平方和（反映方差）\n",
    "取X=ε^即的误差ε的估计量,根据方差性质E(X^2)=E(X)^2+D(X)，可以得知系统偏差和方差的影响。\n",
    "这两个理论为选取误差平方和为聚类分析指标提供了尺度上的把握。\n",
    "极端情况下，单一簇，误差平方和最大，为总离差；\n",
    "         单样本簇，每个簇只有一个数据，误差平方和最小，为零。\n",
    "实际聚类情况，误差平方和达到应用要求的某一控制水平。\n",
    "误差平方和作为聚类的指示指标，是比较方便可行的。\n",
    "\n",
    "优化目标选择了母簇的母子分支的误差平方和降低量，而不是每个母簇分裂方案的总的误差平方和。这是为了程序选拔母簇有更加方便的针对指标，不需要关注总误差，只要具体到谁。\n",
    "\n",
    "母簇新生成时都通过二分聚类做了母子分支，并计算了母簇内的误差平方和降低量。\n",
    "此番改进不像标准的二分聚类程序，缺点是：\n",
    "每增加一个簇，要把各个母簇重复一次二分聚类，相当的重算一遍误差平方和降低量的工作量，而改进的程序仅对新生的母簇做二分聚类和误差统计。\n",
    "改进程序的存储空间保留了当前各本簇中心点、全体样本对各簇的从属关系、统计的本簇的误差项。\n",
    "增加了子簇中心点、各簇内样本对其各子簇的从属关系、子簇内的统计误差项。\n",
    "\n",
    "时空开销的权衡比较：\n",
    "空间最明显的增加就是子簇的从属关系，体量相当于全体样本对各簇的从属关系，增加了一倍的空间开销，但压缩了(K-2)的重复二分聚类和误差统计（最后一步K个聚类）的时间开销。\n",
    "\n",
    "改进的适用情况：\n",
    "   越多的聚类个数，越需要压缩重复二分聚类和误差统计的时间开销，尽管二分聚类每个母簇的样本数也在减小。改进的误差平方和降低量优化方法更加适合。\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "## 细节问题梳理（因果倒推，上因（准备+条件）下果，目标导向思维。）\n",
    "聚类细节上的因果关系清理\n",
    "单一的簇变成母簇                     生成母子分支，但未分裂\n",
    "\n",
    "初始到正常的母簇数量增长过程   \n",
    "                               单一母簇直接分裂  \n",
    "                               不用选择，就是她，没有选择的问题  \n",
    "\n",
    "正常的分裂过程针对多个非单一的母簇  \n",
    "                                   新生成的母簇，母簇之间确定  \n",
    "                                  谁是分裂者，数量至少是2个母簇。  \n",
    "\n",
    "\n",
    "                                   对分裂的母簇二分割聚类生成子簇    \n",
    "已有的各未分裂母子分支的误差平方和降低量      计算各母子分支的误差平方和降低量  \n",
    "\n",
    "\n",
    "已有的母子分支（子簇未分裂出去）            更新的母子分支（子簇分裂出去）  \n",
    "\n",
    "\n",
    "\n",
    "准备好各母子分支，误差平方和降低量  \n",
    "\n",
    " 从各母子分支中选拔误差平方和降低量最大的，聚类个数增加1，更新两子簇为母簇。  \n",
    " 聚类个数达到要求，停止聚类，不再分裂母簇。  \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化的kmeans数据字典\n",
    "\n",
    "术语概念空间：  \n",
    "簇概念空间的划分为两维：本，母，子，新生；中心坐标，所属关系，误差平方项  \n",
    "数据对象：列表、矩阵、数组；生命周期有初始化，使用，更新（生成）  \n",
    "数据对象是簇等术语概念的载体。  \n",
    "\n",
    "术语概念和关系需要根据程序设计来精化，不要搞大而全的覆盖。    \n",
    "同SQL关系数据库一样要做E-R范式依赖关系的分解。  \n",
    "为程序执行提供存储结构（安排一定的数据对象），也要为人的审查提供视图（连接查询）。  \n",
    "E-R分解体现程序设计的精简要义。不能把全连接作为存储和执行单元。  \n",
    "人机的设计和执行单元划分有所不同，人机各界：人的东西要聚合要包容，机的执行和存储要精当，组合连接要灵活，覆盖人的需求。  \n",
    "\n",
    "\n",
    "本簇：\n",
    "本簇（中心坐标，误差平方和SSE） CurrentClusters可分解的复合表\n",
    "currentCentroids表存放本簇中心点坐标√\n",
    "ClusterErrorSum表存放误差平方和SSE√\n",
    "clusterAssment簇所属表，存放所属的簇的中心号，到簇中心的距离平方 √\n",
    "全体样本与所属簇的从属关系：\n",
    "样本⁮点 → 簇中心    （所属簇的中心号，到簇中心的距离平方）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "母簇：本簇的扩展，程序中本簇的主要代表者，不另行命名\n",
    "母簇（Index：本簇中心号，子簇中心坐标,分裂后的残差，子簇划分带来的误差平方和降低量）\n",
    "其中，本簇中心号不用列出，直接排位区分，是索引。\n",
    "newCluster=[newClusterCentroids ID as Index->,subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "                             √      √          \n",
    "都可以分解独立成表\n",
    "最终只取subClusterCentroids,subClusterAss（可导出subClusterErrorSum和splitedError）\n",
    "subClusterErrorSum=[np.sum(clusterAss[clusterAss[:,0]==i, 1]) for i in [0,1]]\n",
    "\n",
    "母簇内两种从属关系：\n",
    "全体样本与所属母簇的从属关系：\n",
    "样本⁮点 → 母簇中心    （所属母簇的中心号，到母簇中心的距离平方）\n",
    "\n",
    "subclusterAss子簇所属表 √\n",
    "簇内样本与子簇的从属关系：\n",
    "本簇内：\n",
    "样本⁮点 → 子簇中心（所属子簇的中心号，到子簇中心的距离平方）\n",
    "\n",
    "#subClusterCentroids,splitedError,subClusterErrorSum,subClusterAss\n",
    "#=newCluster(ptsInCluster,k=2)#ptsInCluster为准母簇\n",
    "\n",
    "子簇：\n",
    "子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表\n",
    "subClusterCentroids表存放子簇中心点坐标√\n",
    "subClusterErrorSum表存放各子簇的误差平方和SSE√    身份只是中间表\n",
    "用于分裂后，转正为ClusterErrorSum表存放误差平方和SSE\n",
    "\n",
    "\n",
    "ErrorDelta表 子簇划分带来的误差平方和降低量，二分割新簇得到的新生母簇时生成，用于分裂母簇选拔。\n",
    "\n",
    "辅助的历史记录表   在母簇分裂时更新\n",
    "discenter表示被分裂的一代代母簇\n",
    " #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量，分裂后的残差平方和，初始为np.inf\n",
    "disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表\n",
    "\n",
    "新生簇（初始条件和循环结束条件）newCluster：\n",
    "新生簇中心表 newClusterCentroids   新生簇的中心点坐标，新生的是两个子簇，故为2组坐标的列表。\n",
    "新生簇的所属表 newClusterAssment\n",
    "新生簇的误差平方和newClusterErrorSum \n",
    "新生簇在当前簇集中的序号Indexes_of_newClusterCentroids_In_currentCentroids\n",
    "新生簇没有ErrorDelta表，因为还没有分裂\n",
    "\n",
    "\n",
    "\n",
    "数据对象的生命周期：\n",
    "注意区分使用和生成（更新）、初始化，以此为线索检查调试程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术小trick\n",
    "#按：注意：0,1两簇的编号如果直接按照needToSplit和len(currentCentroids) 更新\n",
    "        #因为newClusterAssment不能区分编号，会出现干扰。\n",
    "        #为保险起见，needToSplit先不做needToSplit更新，而是采用很大的数值\n",
    "        #大数值例如needToSplit+10000，替换该编号\n",
    "        #不出现混淆时，len(currentCentroids) 更新顺利完成后，needToSplit+10000改回needToSplit\n",
    "        \n",
    "#注意对空簇的处置   \n",
    "\n",
    "#按：重点细节 1号子簇要优先更新，以避免与0号子簇的needToSplit=1干扰情况出现：\n",
    "  0号子簇如果先更新，有可能更新的值needToSplit恰好是1，在1号子簇更新时没有保护，也被更新掉！\n",
    "#获得剩余数据集的误差\n",
    "nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])  \n",
    "                不是从dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]获取误差\n",
    "#newCentroids = centroids#.A  #错误源，不能带.A，这是两个子簇的族，源代码有.A （变为数组）\n",
    "\n",
    "#分组严重的不均衡现象的原因？needToSplit = j的限制  初始化 needToSplit = 0  #提出来\n",
    "#注意：[0]可以把数据从单元素列表中取出\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %load kmeans.py   加载共享的函数和库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load kmeans.py\n",
    "# kmeans/kmeans.py\n",
    "import numpy as np\n",
    "\n",
    "def loadDataSet(filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    读取数据集\n",
    "\n",
    "    Args:\n",
    "        filename: 文件名\n",
    "    Returns:\n",
    "        dataMat: 数据样本矩阵\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 通过map函数批量转换\n",
    "        #fitLine = map(float, curLine)#py3中改为\n",
    "        fitLine =list(map(float, curLine))\n",
    "        dataMat.append(fitLine)\n",
    "    return dataMat\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    \"\"\"\n",
    "    计算两向量的欧氏距离\n",
    "\n",
    "    Args:\n",
    "        vecA: 向量A\n",
    "        vecB: 向量B\n",
    "    Returns:\n",
    "        欧式距离\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.power(vecA - vecB, 2)))\n",
    "\n",
    "def randCent(dataSet, k):\n",
    "    \"\"\"\n",
    "    随机生成k个聚类中心\n",
    "\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 簇数目\n",
    "    Returns:\n",
    "        centroids: 聚类中心矩阵\n",
    "    \"\"\"\n",
    "    _, n = dataSet.shape\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "    for j in range(n):\n",
    "        # 随机聚类中心落在数据集的边界之内\n",
    "        minJ = np.min(dataSet[:, j])\n",
    "        maxJ = np.max(dataSet[:, j])\n",
    "#         print('minJ =',minJ )\n",
    "        rangeJ = float(maxJ - minJ)\n",
    "        \n",
    "        centroids[:, j] = minJ + rangeJ * np.random.rand(k, 1)\n",
    "    return centroids\n",
    "\n",
    "def kMeans(dataSet, k, maxIter = 5):\n",
    "    \"\"\"\n",
    "    K-Means\n",
    "\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    # 随机初始化聚类中心\n",
    "    centroids = randCent(dataSet, k)\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))#按：开始，各子簇簇号都是0号\n",
    "    # 标识聚类中心是否仍在改变\n",
    "    clusterChanged = True\n",
    "    # 直至聚类中心不再变化\n",
    "    #按：补充，发现空簇\n",
    "    kong=k*[0]#各簇 计数，初始值0\n",
    "    iterCount = 0\n",
    "    while clusterChanged and iterCount < maxIter:\n",
    "        iterCount += 1\n",
    "        clusterChanged = False\n",
    "        # 分配样本到簇\n",
    "        for i in range(m):\n",
    "            # 计算第i个样本到各个聚类中心的距离\n",
    "            minIndex = 0\n",
    "            minDist = np.inf\n",
    "            for j in range(k):\n",
    "                dist = distEclud(dataSet[i, :],  centroids[j, :])\n",
    "                if(dist < minDist):\n",
    "                    minIndex = j\n",
    "                    minDist = dist\n",
    "            kong[minIndex]=kong[minIndex] +1       #各簇计数 \n",
    "            # 判断cluster是否改变\n",
    "            if(clusterAssment[i, 0] != minIndex):\n",
    "                clusterChanged = True\n",
    "            clusterAssment[i, :] = minIndex, minDist**2\n",
    "        \n",
    "        #判断是否有空簇  补充代码\n",
    "#         for j in range(k):\n",
    "#             if kong[j]==0:\n",
    "#                 print('出现第',j,'号空簇')\n",
    "        # 刷新聚类中心: 移动聚类中心到所在簇的均值位置\n",
    "        #空簇号kongids\n",
    "        kongids=[]\n",
    "        for cent in range(k):  #按：子簇在母簇内部编号cent\n",
    "            #过滤空簇   补充代码\n",
    "#             if kong[cent]==0:\n",
    "#                 print('出现第',j,'号空簇，现在跳过')\n",
    "#                 kongids.append(cent)#加入空簇号列表\n",
    "#                 continue\n",
    "            # 通过数组过滤获得簇中的点\n",
    "            ptsInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A == cent)[0]]  \n",
    "            #按：clusterAssment[:, 0].A变单列矩阵为数组A\n",
    "            if ptsInCluster.shape[0] > 0:\n",
    "                # 计算均值并移动     \n",
    "                #按：kMeans的由来 适用于数值型变量，本质是取序。\n",
    "                #因此，为避免极端值对均值的影响，kMeans不是不能用，而是要经过每维序号化预处理。\n",
    "                #序号化的中值设定为0，小端为负，大端为正。\n",
    "                centroids[cent, :] = np.mean(ptsInCluster, axis=0) #注： centroids是矩阵,本行可见\n",
    "    return centroids, clusterAssment#,kong,kongids #分别进行频率计数和空簇统计  \n",
    "def newCluster(ptsInCluster,k=2):#母簇ptsInCluster生成k=2分割的子簇,母簇号不用携带\n",
    "    #预备抽象的模块newCluster(ptsInCluster,k),\n",
    "    #返回newCluster=[newClusterCentroids,subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "    centroids, clusterAss = kMeans(ptsInCluster, k)\n",
    "    #按：此步为优化考虑点，不需要每次新增一簇就对全部的旧簇反复做二分聚类，仅仅针对新增的簇做二分聚类，并保存。\n",
    "    # 获得划分后的误差之和\n",
    "    \n",
    "    #不再承担老簇的统计，只需要统计本簇的新残差平方和\n",
    "#     m=len(ptsInCluster)\n",
    "#     centroid0 = np.mean(ptsInCluster, axis=0).tolist()[0]\n",
    "#     clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "#     for j in range(m):\n",
    "#         clusterAssment[j, 1] = distEclud(ptsInCluster[j, :], np.mat(centroid0))**2             \n",
    "#     oldClusterAssment=clusterAssment\n",
    "#     oldClusterErrorSum=np.sum(oldClusterAssment[:, 1])  \n",
    "            \n",
    "    splitedError= np.sum(clusterAss[:, 1])#新残差平方和\n",
    "#     ErrorDelta=oldClusterErrorSum-splitedError#不承担统计此功能\n",
    "#[[np.sum([a[i][1] for i in  range(len(a)) if a[i][0]==j])] for j in [0,1]] #可行的参考\n",
    "    subClusterErrorSum=[[np.sum([clusterAss[i,1] for i in  range(len(clusterAss)) \n",
    "                                 if clusterAss[i,0]==j])] for j in [0,1]]   \n",
    "    subClusterCentroids=centroids\n",
    "    subClusterAss=clusterAss\n",
    "\n",
    "    #以下两个等效动作是分裂动作，从子簇身份生成新簇，这是在选拔过程中完成的\n",
    "    #本过程是要确定母子分支，当好母簇。\n",
    "    #动作1\n",
    "#     newCluster0=[subClusterCentroids.tolist()[0],[],splitedError,ErrorDelta,subclusterAss]\n",
    "#     newCluster1=[subClusterCentroids.tolist()[1],[],splitedError,ErrorDelta,subclusterAss]\n",
    "#     newCluster=[newCluster0,newCluster1]\n",
    "    #动作2\n",
    "#     newCluster=[]\n",
    "#     for i in [0,1]:\n",
    "#         print(subClusterCentroids[i],'/n',i)        \n",
    "#         newCluster.append([subClusterCentroids[i],[],splitedError,ErrorDelta,subclusterAss[i]])\n",
    "#         #extend是对列表；append是对元素\n",
    "    #正确动作：返回母子分支，当好母簇\n",
    "#     newCluster=[[],subClusterCentroids,splitedError,ErrorDelta,subclusterAss]\n",
    "    #ErrorDelta不在放入了，改为subClusterErrorSum\n",
    "    newCluster=[subClusterCentroids,splitedError,subClusterErrorSum,subClusterAss]\n",
    "    print('type(subClusterCentroids)=',type(subClusterCentroids))\n",
    "    print('本身type(subClusterAss)=',type(subClusterAss))#矩阵\n",
    "                        #但在优化的。。。，下游，缺失#type of newClusterAssment= <class 'list'>\n",
    "    \n",
    "    return newCluster  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准的biKmeans    原load的py文件已改好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):     #ok的\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "        lowestError = np.inf\n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            centroids, clusterAss = kMeans(ptsInCurrCluster, 2)\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])\n",
    "            \n",
    "            print(\"splitedError, and nonSplitedError: \",splitedError,nonSplitedError)\n",
    "            # 比较，判断此次划分是否划算\n",
    "            if (splitedError + nonSplitedError) < lowestError:\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A    #按：0,1两族子簇\n",
    "#                 newCentroids = centroids#.A  #错误源，不是.A，源代码有.A\n",
    "                newClusterAss = clusterAss.copy()\n",
    "                # 如果划算，刷新总误差\n",
    "                lowestError = splitedError + nonSplitedError\n",
    "\n",
    "\n",
    "        # 更新簇的分配结果   \n",
    "        #按：重点细节 1号子簇要优先更新，以避免与needToSplit=1干扰：\n",
    "        #0号子簇如果先更新，有可能更新的值needToSplit恰好是1，在1号子簇更新时没有保护，也被更新掉！\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "\n",
    "        print( 'the bestCentToSplit -needToSplit is: ', needToSplit)\n",
    "        print ('the len of bestClustAss -newClusterAss is: ', len(newClusterAss))\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "    return np.mat(currentCentroids), clusterAssment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 扩展一下biKmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):  #有小幅改动  运行ok！\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    #按：二分kmeans有不均衡聚类的倾向。\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    J=0\n",
    "    TotalError=[]\n",
    "    \n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "#         lowestError = np.inf\n",
    "        HighestError=0\n",
    "        TotalError.append(0)\n",
    "        Delta=[]#按：补充测试，存放DeltaErro\n",
    "        for j in range(len(currentCentroids)):\n",
    "             TotalError[J]+=clusterAssment[j, 1]\n",
    "                \n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "#             print('ptsInCluster:',ptsInCluster)#按：补充测试\n",
    "            print('len(ptsInCluster)',len(ptsInCluster))\n",
    "            ptsInClusterError = np.sum(ptsInCluster[:, 1])\n",
    "#             if len(ptsInCluster)==0:#空簇处置：新增代码 删除该中心，跳到下一for j循环\n",
    "#                 del(currentCentroids[j])\n",
    "#                 continue\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            \n",
    "            centroids, clusterAss = kMeans(ptsInCluster, 2)#按：权衡，时间和空间\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            DeltaError0=ptsInClusterError-splitedError\n",
    "            Delta.append(DeltaError0)\n",
    "            #求平均的误差降落\n",
    "            DeltaError= DeltaError0/(len(ptsInCluster)-1)\n",
    "            \n",
    "            #按：原文错误，下行做了替换\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "                        # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差  #按：替换的这一行\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])           \n",
    "                        \n",
    "            # 比较，判断此次划分是否划算\n",
    "#             if DeltaError/TotalError[J]<lowestError:\n",
    "#             if DeltaError<lowestError:\n",
    "            if DeltaError<HighestError:\n",
    "#                 lowestError=DeltaError/TotalError[J]\n",
    "#                 lowestError=DeltaError\n",
    "                HighestError=DeltaError\n",
    "#             if (splitedError + nonSplitedError) < lowestError:\n",
    "#                 # 如果划算，刷新总误差\n",
    "#                 lowestError = splitedError + nonSplitedError\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A  #错误源，不是.A，源代码有.A\n",
    "                newClusterAss = clusterAss.copy()#按：三个位置，搞不好就出错\n",
    "        # 更新簇的分配结果  #注意顺序，子簇1优先，不会串扰\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "#         print('currentCentroids=',currentCentroids)#按：补充测试\n",
    "        J+=1\n",
    "        print('第',J,'轮的len of newClusterAss=',len(newClusterAss))\n",
    "        print('取代第',needToSplit,'号母簇','0号子簇长度',len(newClusterAss[:, 0].A == 0))\n",
    "            #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "#     currentCentroids=np.vstack(currentCentroids)\n",
    "    print('Delta=',Delta)\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本人优化的biKmeans_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def biKmeans_(dataSet, k):   #按：改进二分聚类，不需要每次新增一簇就对全部的旧簇反复做二分聚类。\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    \n",
    "    #本簇的初始化，包括中心，所属，误差三项\n",
    "#     CurrentClusters=[]#初始化为分割前的当前的簇列表  #复合表，取消掉\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    " \n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "\t#循环初始化新簇，补充的代码\n",
    "    #新簇是为了二分支形成母簇而用\n",
    "\n",
    "    ClusterErrorSum=[[]]#此表存放误差平方和SSE  不能是[]\n",
    "    \n",
    "    \n",
    "    #子簇：\n",
    "    #子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表 ，未使用\n",
    "    #子簇的初始化，也包括中心，所属，误差三项   \n",
    "    subClusterCentroids=[[]]#子簇中心坐标表\n",
    "    subClusterAss=[[]]      #子簇所属表（所属子簇中心号，误差平方），可导出下列二项：\n",
    "    subClusterErrorSum=[[]]  #各子簇的误差平方和\n",
    "    splitedError=[[]]        #母簇分裂后的误差平方和，上述两子簇误差平方和相加\n",
    "    ErrorDelta=[[]]  #初始误差平方和降低量\n",
    "    #注：[[]]的初始值比[]有更多的灵活性，不是一直append，还可以杀回马枪从取空[]的a[i].append()添加元素\n",
    "\n",
    "\n",
    "\n",
    "    #新生簇的初始化，也包括中心，所属，误差三项 ，为了和循环衔接  \n",
    "    newClusterCentroids=currentCentroids \n",
    "    newClusterAssment=clusterAssment\n",
    "    newClusterErrorSum=np.sum(newClusterAssment[:, 1]) #新簇的误差平方和\n",
    "    Indexes_of_newClusterCentroids_In_currentCentroids=[0]#新生簇在当前簇集中的序号\n",
    "#     ClusterErrorSum.append(newClusterErrorSum)#错误，改为下面的\n",
    "    ClusterErrorSum[0].append(newClusterErrorSum)\n",
    "\n",
    "    \n",
    "#     辅助的历史记录表   在母簇分裂时更新\n",
    "#     discenter=[] #可能直接用不上，是复合表\n",
    "    #初值可取[newClusterCentroids,newClusterErrorSum]   \n",
    "    #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量，分裂后的残差平方和\n",
    "    #disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表\n",
    "    disCenterIDs=[]\n",
    "    disCentroids=[]\n",
    "    disErrorSum=[]\n",
    "    disErrorDelta=[]\n",
    "    dissplitedError=[]\n",
    "    \n",
    "    needToSplit = 0 #提出来   初始化\n",
    " \n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "    # 直到簇的数目达标\n",
    "#     if len(currentCentroids) < k:    #按：要<而不是≤，循环结束时就已经生成全部k个中心点，k-1+1=k个簇\n",
    "        # 当前最小的代价\n",
    "        highestErrorDelta = 0\n",
    "        # 对于每一个簇    #按：改为，对每一个新簇，存储二分聚类的两个子簇，还有误差平方和及其二分聚类的降低量。     \n",
    "    \n",
    "        for j in Indexes_of_newClusterCentroids_In_currentCentroids:\n",
    "            # 获得该簇的样本           \n",
    "#             ptsInCluster = dataSet[np.nonzero(newClusterAssment[:, 0].A == j)[0], :]\n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:,0].A == j)[0], :]\n",
    "            # 在该簇上进行2-means聚类\n",
    "            newClusterPre=newCluster(ptsInCluster,2)      \n",
    "            #返回subClusterCentroids,splitedError,subClusterErrorSum,subclusterAss\n",
    "            #                二立 ， 单立，           二立，         原样本混沌不分\n",
    "#             print('newClusterPre[3]=',newClusterPre[3])\n",
    "            print('type(newClusterPre[3])=',type(newClusterPre[3]))\n",
    "            #按：测试结果： type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
    "            subClusterCentroids[j].extend(newClusterPre[0])#更新j的[] ,这是二立情况\n",
    "            #按：要注意append和extend的区别！extend针对列表合并，append针对元素的追加\n",
    "            print('append的subClusterCentroids=',subClusterCentroids[j])\n",
    "            #append的subClusterCentroids= [[matrix([[-0.2897198 , -2.83942545]])]]\n",
    "            splitedError[j].append(newClusterPre[1])\n",
    "            subClusterErrorSum[j].append(newClusterPre[2])#这是二立情况\n",
    "#             subClusterAss[j].append(newClusterPre[3]) #按：[j]不可省掉，否则反复乱下去。重点细节\n",
    "            subClusterAss[j].append(newClusterPre[3]) #  不宜用extend，否则得到一行行materix碎片\n",
    "            print('ClusterErrorSum[',j,']=',ClusterErrorSum[j])#得 ClusterErrorSum[ 0 ]= [1465.5800234838164]\n",
    "            print('splitedError[',j,']=',splitedError[j]) #得 splitedError[ 0 ]= [828.6926539968681]\n",
    "            print('ClusterErrorSum[',j,'][0]=',ClusterErrorSum[j][0])#得 ClusterErrorSum[ 0 ]= [1465.5800234838164]\n",
    "            print('splitedError[',j,'][0]=',splitedError[j][0]) #得 splitedError[ 0 ]= [828.6926539968681]\n",
    "            ErrorDelta[j].append((ClusterErrorSum[j][0]-splitedError[j][0]))#这是单立情况\n",
    "            #注意：[0]可以把数据从单元素列表中取出\n",
    "            #             ErrorDelta[j].append([ClusterErrorSum[j]-splitedError[j]])#原始写法出错\n",
    "            #出错TypeError: unsupported operand type(s) for -: 'list' and 'list'\n",
    "\n",
    "        # 比较，判断此次划分是否划算\n",
    "#         currentClusters=np.mat(CurrentClusters) #当前的簇矩阵\n",
    "#             print('currentClusters[j,:]',currentClusters[j,:])\n",
    "        print('&&&&&&&&&&&&&&&&&&&&&&ErrorDelta&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&')\n",
    "        print(ErrorDelta)\n",
    "        for j in range(len(currentCentroids)):\t\n",
    "            #needToSplit = j #不应放在此处，会导致不均衡\n",
    "            if ErrorDelta[j][0] >highestErrorDelta :#& len(currentCentroids)>1:\n",
    "                #ErrorDelta[j] >....写法出错TypeError: '>' not supported between instances of 'list' and 'int'\n",
    "                #按：currentClusters[j,3]即ErrorDelta\n",
    "                # 如果还有更大降低量，刷新误差平方和的最大降低量\n",
    "                highestErrorDelta = ErrorDelta[j][0]\n",
    "                print('ErrorDelta[',j,'][0]=',ErrorDelta[j][0])\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果  #按：选拔要分裂的那个母簇\n",
    "        print('needToSplit=',needToSplit)\n",
    "#         print('subClusterAss[needToSplit]=',subClusterAss[needToSplit])\n",
    "#         newCentroids =currentCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列   错误，这是单簇了\n",
    "        newCentroids =subClusterCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列\n",
    "        print('newCentroids=',newCentroids)\n",
    "        print('type of newCentroids=',type(newCentroids))\n",
    "#         newClusterAssment =clusterAssment[needToSplit]#按：子簇所属子簇号0或1，距离子簇中心平方不用动\n",
    "        newClusterAssment =subClusterAss[needToSplit][0] #按：列表subClusterAss[needToSplit]取首元素，加[0]\n",
    "#         print('newClusterAssment=',newClusterAssment)\n",
    "        print('工作点 type of newClusterAssment=',type(newClusterAssment))\n",
    "        #按：newClusterAssment =subClusterAss[needToSplit]的\n",
    "        #测试结果为 type of newCentroids= <class 'list'>，后面的矩阵用法要加上[0]\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        #重点：找到错误根源所属关系矩阵或表，不能直接用needToSplit来给，它不是序号或行号，而是元素的首位数值\n",
    "        print('clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape=',\n",
    "              clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape)        \n",
    "#         print('待分裂的currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('len(currentCentroids)=',len(currentCentroids),'选第',needToSplit,'号母簇')\n",
    "        print('下面的0、1子簇，中心为：',newCentroids)\n",
    "        '''\n",
    "        '''\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 1)[\n",
    "            0], 0] =len(currentCentroids) \n",
    "        #TypeError: list indices must be integers or slices, not tuple \n",
    "        #出错源在newClusterAssment更新用了[[]]，而不是[]!\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 0)[  #按：np.nonzero()，()内非零的逻辑判断，取逻辑真。\n",
    "            0], 0]=needToSplit  \n",
    "        #保护0号子簇，前面1号子簇的序号len(currentCentroids)>0 ，不会冲突。 \n",
    "        #反过来，先更新0号子簇为needToSplit，如果needToSplit恰好为1，接下来更新1号子簇时，继续被更新。\n",
    "        \n",
    "        #len(np.nonzero(newClusterAssment[:, 0].A == 1)[0])*[len(currentCentroids)]\n",
    "        #按：len(currentCentroids) ?不对\n",
    "        #按：实际的簇号增加了，从len(currentCentroids)-1变为len(currentCentroids)\n",
    "        \n",
    "        #以下两行废弃，改为第三行\n",
    "        #newClusterErrorSum=[]\n",
    "        #newClusterErrorSum.extend(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        newClusterErrorSum=subClusterErrorSum[needToSplit][0]\n",
    "        #仿效 newClusterAssment =subClusterAss[needToSplit][0]，不用下面的\n",
    "#         newClusterErrorSum.append(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        print('newClusterErrorSum=',newClusterErrorSum,'for needToSplit=',needToSplit)\n",
    "        #测得newClusterErrorSum= [[[466.63278133614426], [326.28407520118242]]] for needToSplit= 0\n",
    "#         print('检查newClusterAssment种类',np.unique(newClusterAssment[:, 0].A))\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        #本簇更新：分裂的母簇更新为新簇：\n",
    "        #保存历史记录（中心号，中心点坐标，误差项）\n",
    "        #依次更新两子簇的：误差项，从属关系，中心点\n",
    "        \n",
    "        # 1/4        分裂的母簇更新之前保存历史记录\n",
    "                #         被选的母簇的分裂动作，善后安排\n",
    "        \n",
    "        disCenterIDs.append(needToSplit)\n",
    "        disCentroids.append(currentCentroids[needToSplit])\n",
    "        disErrorSum.append(ClusterErrorSum[needToSplit])\n",
    "        disErrorDelta.append(ErrorDelta[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        dissplitedError.append(splitedError[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        \n",
    "        #2/4 误差项更新   注意区分使用和生成（更新）\n",
    "        #检查，已做掉的：\n",
    "        #ErrorDelta（确定分裂母簇时使用）\n",
    "        #splitedError、subClusterErrorSum 各子簇的误差平方和  新簇二分支形成母簇时使用，生成则在母簇分裂时\n",
    "        print('newClusterErrorSum[0]=',newClusterErrorSum[0])#测得 newClusterErrorSum[0]= [32.601242864951153]\n",
    "        ClusterErrorSum[needToSplit]=newClusterErrorSum[0]\n",
    "        ClusterErrorSum.append(newClusterErrorSum[1])\n",
    "        \n",
    "        splitedError[needToSplit]=[]\n",
    "        splitedError.append([])\n",
    "        subClusterErrorSum[needToSplit]=[]\n",
    "        subClusterErrorSum.append([]) \n",
    "        ErrorDelta[needToSplit]=[]\n",
    "        ErrorDelta.append([]) \n",
    "        \n",
    "        #3/4 从属关系更新    包括本簇的和分裂的子簇的\n",
    "        #本簇的从属关系更新\n",
    "        # 刷新点分配结果    #按：所属簇号  即从属关系更新\n",
    "        print('$$$$$$$$$$$$$$$$$$$$$本簇的从属关系更新$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        print('len of clusterAssment: needToSplit=',len(clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :]))\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAssment  \n",
    "        print('np.unique(newClusterAssment[:, 0].A)=',np.unique(newClusterAssment[:, 0].A))\n",
    "        print('np.unique(clusterAssment[:, 0].A)=',np.unique(clusterAssment[:, 0].A ))\n",
    "        #按：原簇簇号为needToSplit的样本被新的二分簇族（注意：是族）\n",
    "        #                                             newClusterAss取代\n",
    "        #簇号不变  \n",
    "        #按：discenter表示被分裂的一代代母簇\n",
    "        #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量\n",
    "        #子簇的从属关系更新\n",
    "        subClusterAss[needToSplit]=[]#注意：不是[[]]\n",
    "        subClusterAss.extend([[]])\n",
    "        #4/4 中心点更新,包括本簇中心点更新currentCentroids和子簇中心点更新subClusterCentroids（重点：不能忽视）\n",
    "        #本簇中心点更新currentCentroids\n",
    "#         print('currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "         # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0]#.tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        print('newCentroids[1]=',newCentroids[1]) #按：newCentroids[1]是单坐标点的列表[[单坐标点]]\n",
    "        #newCentroids[1]= [[-3.38237045 -2.9473363 ]]  #返回一单行的矩阵[[]]  #重点关注，矩阵而非列表\n",
    "#         currentCentroids.extend(newCentroids[1])#.tolist()[0])#加了.tolist()[0] #按：注意append和extend差别\n",
    "        currentCentroids.append(newCentroids[1])#.tolist()[0]\n",
    "        print('currentCentroids[-1]',currentCentroids[-1])\n",
    "        print('currentCentroids[-1][0]',currentCentroids[-1][0])\n",
    "        #子簇中心点更新subClusterCentroids\n",
    "        subClusterCentroids[needToSplit]=[]\n",
    "#         subClusterCentroids.extend([])  #按：考察功底的时刻\n",
    "#         subClusterCentroids.extend([])    #按：等于什么也没干\n",
    "        subClusterCentroids.extend([[]])  #按：增加了空位，即插入了[]，该序号i是可以用[i]append()来补充元素的\n",
    "#         subClusterCentroids.append([[]])  #按：增加了元素[[]]，插入的是空元素的单元素表\n",
    "        print('subClusterCentroids=',subClusterCentroids)\n",
    "      \n",
    "  \n",
    "        #按：一对分裂的子簇变成一对新生簇，内部二分割变成待选分裂的母簇\n",
    "#         newClusterCentroids=[]\n",
    "#         newClusterCentroids.append(currentCentroids[needToSplit])\n",
    "#         newClusterCentroids.append(currentCentroids[-1])\n",
    "        Indexes_of_newClusterCentroids_In_currentCentroids=[needToSplit,len(currentCentroids)-1]\n",
    "        print('Indexes_of_newClusterCentroids_In_currentCentroids=',Indexes_of_newClusterCentroids_In_currentCentroids)    \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('#####################################################################################')\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "    #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "    currentCentroids=np.vstack(currentCentroids)\n",
    "#         currentCentroids\n",
    "    print('最终的ErrorDelta=',ErrorDelta)\n",
    "    print('最终的disErrorDelta=',disErrorDelta)\n",
    "        \n",
    "#     return np.mat(currentCentroids), clusterAssment\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主调main  ：作为测试口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行时间 0.2689971923828125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ccba9ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load test_normal_kmeans.py\n",
    "# kmeans/test_normal_kmeans.py\n",
    "import time as tm\n",
    "import kmeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#按：在Notepad++中运行python脚本 cmd /k D:\\ProgramData\\Anaconda2\\envs\\py3\\python.exe \"$(FULL_CURRENT_PATH)\" & PAUSE & EXIT\n",
    "if __name__ == \"__main__\":\n",
    "    s=tm.time()\n",
    "    dataMat = np.mat(loadDataSet('data/testSet.txt'))#kmeans.\n",
    "    centroids, clusterAssment = kMeans(dataMat,6) \n",
    "    #6运行时间 0.2689971923828125\n",
    "    #6运行时间 0.2850019931793213\n",
    "    #6运行时间 0.2919943332672119\n",
    "    #kmeans.2运行时间  0.08598971366882324\n",
    "#     centroids, clusterAssment = biKmeans(dataMat, 6)\n",
    "    #6运行时间 0.39299678802490234\n",
    "    #6运行时间 0.42099523544311523\n",
    "    #6运行时间 0.3880009651184082 \n",
    "    #2运行时间 0.072998046875\n",
    "#     centroids, clusterAssment = biKmeans_(dataMat,6)  \n",
    "    #6运行时间 0.3679966926574707  \n",
    "    #6运行时间 0.3579981327056885\n",
    "    #6运行时间 0.28999781608581543  \n",
    "    #2运行时间 0.11799740791320801\n",
    "    clusterCount = np.shape(centroids)[0]\n",
    "    m = np.shape(dataMat)[0]\n",
    "    print('运行时间',tm.time()-s)\n",
    "    # 绘制散点图\n",
    "    patterns = ['o', 'D', '^', 's','*','P','H','x']   #discent消失的中心备用'v'倒三角\n",
    "    colors = ['b', 'g', 'y', 'black','c','r','m','w']\n",
    "    #补充：颜色参数：\n",
    "#b--blue    c--cyan    g--green  k--black\n",
    "#m--magenta r--red     w--white  y--yellow\n",
    "    fig = plt.figure()\n",
    "    title = 'kmeans with k='+str(clusterCount)\n",
    "    ax = fig.add_subplot(111, title=title)\n",
    "    for k in range(clusterCount):\n",
    "        # 绘制聚类中心    #color='r修改，以便辨认\n",
    "        #空簇处理放在biKmeans等中\n",
    "        ax.scatter(centroids[k, 0], centroids[k, 1], color=str(colors[k]), marker='+', linewidth=20)\n",
    "        for i in range(m):\n",
    "            # 绘制属于该聚类中心的样本\n",
    "            ptsInCluster = dataMat[np.nonzero(clusterAssment[:, 0].A==k)[0]]\n",
    "            ax.scatter(ptsInCluster[:, 0].flatten().A[0], ptsInCluster[:, 1].flatten().A[0], marker=patterns[k], color=colors[k])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 汇总各种方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 专门biKmeans代码      ok的！\n",
    "https://www.cnblogs.com/MrLJC/p/4129700.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k, distMeas=distEclud):\n",
    "    #def distEclud(vecA, vecB):\n",
    "    m =np.shape(dataSet)[0]\n",
    "    clusterAssment =np.mat(np.zeros((m,2)))#记录簇分配的结果及误差\n",
    "    centroid0 =np.mean(dataSet, axis=0).tolist()[0]#计算整个数据集的质心\n",
    "    centList =[centroid0] #create a list with one centroid\n",
    "    for j in range(m):#计算初始聚类点与其他点的距离\n",
    "        clusterAssment[j,1] = distMeas(np.mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k):\n",
    "        lowestSSE = np.inf\n",
    "        for i in range(len(centList)):#尝试划分每一簇\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:]#get the data points currently in cluster i\n",
    "#             ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)            \n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2)#后面参数, distMeas)#对这个簇运行一个KMeans算法，k=2\n",
    "            sseSplit = sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            sseNotSplit = sum(clusterAssment[np.nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print(\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:##划分后更好的话\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) #更新簇的分配结果change 1 to 3,4, or whatever\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit\n",
    "        print( 'the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print ('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[np.nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return np.mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准biKmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k):     #ok的\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "        # 当前最小的代价\n",
    "        lowestError = np.inf\n",
    "        # 对于每一个簇\n",
    "        for j in range(len(currentCentroids)):\n",
    "            # 获得该簇的样本\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0], :]\n",
    "            print('ptsInCurrCluster.shape=',ptsInCurrCluster.shape)\n",
    "            # 在该簇上进行2-means聚类\n",
    "            # 注意，得到的centroids，其聚类编号含0，1\n",
    "            centroids, clusterAss = kMeans(ptsInCurrCluster, 2)\n",
    "            # 获得划分后的误差之和\n",
    "            splitedError = np.sum(clusterAss[:, 1])\n",
    "            '''\n",
    "            # 获得其他簇的样本\n",
    "            ptsNoInCluster = dataSet[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]]\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(ptsNoInCluster[:, 1])\n",
    "            '''\n",
    "            # 获得剩余数据集的误差\n",
    "            nonSplitedError = np.sum(clusterAssment[np.nonzero(\n",
    "                clusterAssment[:, 0].A != j)[0]][:, 1])\n",
    "            \n",
    "            print(\"splitedError, and nonSplitedError: \",splitedError,nonSplitedError)\n",
    "            # 比较，判断此次划分是否划算\n",
    "            if (splitedError + nonSplitedError) < lowestError:\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果\n",
    "                newCentroids = centroids#.A\n",
    "                newClusterAss = clusterAss.copy()\n",
    "                # 如果划算，刷新总误差\n",
    "                lowestError = splitedError + nonSplitedError\n",
    "\n",
    "\n",
    "        # 更新簇的分配结果\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 1)[\n",
    "            0], 0] = len(currentCentroids)\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAss[np.nonzero(newClusterAss[:, 0].A == 0)[\n",
    "            0], 0] = needToSplit\n",
    "        print( 'the bestCentToSplit -needToSplit is: ', needToSplit)\n",
    "        print ('the len of bestClustAss -newClusterAss is: ', len(newClusterAss))\n",
    "        # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0, :].tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        currentCentroids.append(newCentroids[1, :].tolist()[0])#加了.tolist()[0]\n",
    "        # 刷新点分配结果\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAss\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出的改进二分聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans_(dataSet, k):   #按：改进二分聚类，不需要每次新增一簇就对全部的旧簇反复做二分聚类。\n",
    "    \"\"\"\n",
    "    二分kmeans算法\n",
    "    Args:\n",
    "        dataSet: 数据集\n",
    "        k: 聚类数\n",
    "    Returns:\n",
    "        centroids: 聚类中心\n",
    "        clusterAssment: 点分配结果\n",
    "    \"\"\"\n",
    "    m, n = np.shape(dataSet)\n",
    "    # 起始时，只有一个簇，该簇的聚类中心为所有样本的平均位置    \n",
    "    #本簇的初始化，包括中心，所属，误差三项\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 设置一个列表保存当前的聚类中心\n",
    "    currentCentroids = [centroid0]\n",
    "    # 点分配结果： 第一列指明样本所在的簇，第二列指明该样本到聚类中心的距离 \n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化点分配结果，默认将所有样本先分配到初始簇\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distEclud(dataSet[j, :], np.mat(centroid0))**2\n",
    "\t#循环初始化新簇，补充的代码\n",
    "    #新簇是为了二分支形成母簇而用\n",
    "    \n",
    "    ClusterErrorSum=[[]]#此表存放误差平方和SSE  不能是[]\n",
    "    #子簇：\n",
    "    #子簇（中心坐标，误差平方和SSE） SubClusters可分解的复合表 ，未使用\n",
    "    #子簇的初始化，也包括中心，所属，误差三项   \n",
    "    subClusterCentroids=[[]]#子簇中心坐标表\n",
    "    subClusterAss=[[]]      #子簇所属表（所属子簇中心号，误差平方），可导出下列二项：\n",
    "    subClusterErrorSum=[[]]  #各子簇的误差平方和\n",
    "    splitedError=[[]]        #母簇分裂后的误差平方和，上述两子簇误差平方和相加\n",
    "    ErrorDelta=[[]]  #初始误差平方和降低量\n",
    "\n",
    "    #新生簇的初始化，也包括中心，所属，误差三项 ，为了和循环衔接  \n",
    "    newClusterCentroids=currentCentroids \n",
    "    newClusterAssment=clusterAssment\n",
    "    newClusterErrorSum=np.sum(newClusterAssment[:, 1]) #新簇的误差平方和\n",
    "    Indexes_of_newClusterCentroids_In_currentCentroids=[0]#新生簇在当前簇集中的序号\n",
    "#     ClusterErrorSum.append(newClusterErrorSum)#错误，改为下面的\n",
    "    ClusterErrorSum[0].append(newClusterErrorSum)\n",
    "    \n",
    "#     辅助的历史记录表   在母簇分裂时更新\n",
    "#     discenter=[] #可能直接用不上，是复合表\n",
    "    #初值可取[newClusterCentroids,newClusterErrorSum]   \n",
    "    #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量，分裂后的残差平方和\n",
    "    #disCenterIDs表，disCentroids表，disErrorSum表，disErrorDelta表，dissplitedError表\n",
    "    disCenterIDs=[]\n",
    "    disCentroids=[]\n",
    "    disErrorSum=[]\n",
    "    disErrorDelta=[]\n",
    "    dissplitedError=[]\n",
    "    \n",
    "    needToSplit = 0  #提出来\n",
    " \n",
    "    # 直到簇的数目达标\n",
    "    while len(currentCentroids) < k:\n",
    "    # 直到簇的数目达标\n",
    "#     if len(currentCentroids) < k:    #按：要<而不是≤，循环结束时就已经生成全部k个中心点，k-1+1=k个簇\n",
    "        # 当前最小的代价\n",
    "        highestErrorDelta = 0\n",
    "        # 对于每一个簇    #按：改为，对每一个新簇，存储二分聚类的两个子簇，还有误差平方和及其二分聚类的降低量。    \n",
    "    \n",
    "        for j in Indexes_of_newClusterCentroids_In_currentCentroids:\n",
    "            # 获得该簇的样本           \n",
    "            ptsInCluster = dataSet[np.nonzero(clusterAssment[:,0].A == j)[0], :]\n",
    "            # 在该簇上进行2-means聚类\n",
    "            newClusterPre=newCluster(ptsInCluster,2)      \n",
    "            #返回subClusterCentroids,splitedError,subClusterErrorSum,subclusterAss\n",
    "            print('type(newClusterPre[3])=',type(newClusterPre[3]))\n",
    "            #按：测试结果： type(newClusterPre[3])= <class 'numpy.matrixlib.defmatrix.matrix'>\n",
    "            subClusterCentroids[j].extend(newClusterPre[0])#更新j的[] \n",
    "            #按：要注意append和extend的区别！extend针对列表合并，append针对元素的追加\n",
    "            print('append的subClusterCentroids=',subClusterCentroids[j])\n",
    "            #append的subClusterCentroids= [[matrix([[-0.2897198 , -2.83942545]])]]\n",
    "            splitedError[j].append(newClusterPre[1])\n",
    "            subClusterErrorSum[j].append(newClusterPre[2])\n",
    "#             subClusterAss[j].append(newClusterPre[3]) #按：[j]不可省掉，否则反复乱下去。重点细节\n",
    "            subClusterAss[j].append(newClusterPre[3]) #  不宜用extend，否则得到一行行materix碎片\n",
    "            print('ClusterErrorSum[',j,'][0]=',ClusterErrorSum[j][0])\n",
    "            print('splitedError[',j,'][0]=',splitedError[j][0]) \n",
    "            ErrorDelta[j].append((ClusterErrorSum[j][0]-splitedError[j][0]))\n",
    "\n",
    "        # 比较，判断此次划分是否划算\n",
    "        for j in range(len(currentCentroids)):\t\n",
    "#             needToSplit = j#不能放在此处，否则大块的簇分割不掉！\n",
    "            if ErrorDelta[j][0] >highestErrorDelta:# & len(currentCentroids)>1:\n",
    "                # 如果还有更大降低量，刷新误差平方和的最大降低量\n",
    "                highestErrorDelta = ErrorDelta[j][0]\n",
    "                # 记录当前的应当划分的簇\n",
    "                needToSplit = j\n",
    "                # 新获得的簇以及点分配结果  #按：选拔要分裂的那个母簇\n",
    "#         newCentroids =currentCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列   错误，这是单簇了\n",
    "        newCentroids =subClusterCentroids[needToSplit] #按：两组子簇中心按子簇号0、1排列\n",
    "        print('newCentroids=',newCentroids)\n",
    "        print('type of newCentroids=',type(newCentroids))\n",
    "        newClusterAssment =subClusterAss[needToSplit][0] \n",
    "#         print('newClusterAssment=',newClusterAssment)\n",
    "        print('工作点 type of newClusterAssment=',type(newClusterAssment))\n",
    "        #按：newClusterAssment =subClusterAss[needToSplit]的\n",
    "        #测试结果为 type of newCentroids= <class 'list'>，后面的矩阵用法要加上[0]\n",
    "        print('len of newClusterAssment=',len(newClusterAssment))\n",
    "        #重点：找到错误根源所属关系矩阵或表，不能直接用needToSplit来给，它不是序号或行号，而是元素的首位数值\n",
    "        print('clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape=',\n",
    "              clusterAssment[np.where(clusterAssment[:,0]==needToSplit)[0],:].shape)        \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('len(currentCentroids)=',len(currentCentroids),'选第',needToSplit,'号母簇')\n",
    "        print('下面的0、1子簇，中心为：',newCentroids)\n",
    "        '''\n",
    "        '''\n",
    "        # 第1簇应当修正为最新一簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 1)[\n",
    "            0], 0] =len(currentCentroids) #TypeError: list indices must be integers or slices, not tuple\n",
    "        # 第0簇应当修正为被划分的簇\n",
    "        newClusterAssment[np.nonzero(newClusterAssment[:, 0].A == 0)[  #按：np.nonzero()，()内非零的逻辑判断，取逻辑真。\n",
    "            0], 0]=needToSplit  \n",
    "\n",
    "        #以下两行废弃，改为第三行\n",
    "        #newClusterErrorSum=[]\n",
    "        #newClusterErrorSum.extend(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        newClusterErrorSum=subClusterErrorSum[needToSplit][0]\n",
    "        #仿效 newClusterAssment =subClusterAss[needToSplit][0]，不用下面的\n",
    "#         newClusterErrorSum.append(subClusterErrorSum[needToSplit])#注意：这里不是append,不针对元素，而是列表\n",
    "        print('newClusterErrorSum=',newClusterErrorSum,'for needToSplit=',needToSplit)\n",
    "        #测得newClusterErrorSum= [[[466.63278133614426], [326.28407520118242]]] for needToSplit= 0\n",
    "\n",
    "        \n",
    "        #本簇更新：分裂的母簇更新为新簇：\n",
    "        #保存历史记录（中心号，中心点坐标，误差项）\n",
    "        #依次更新两子簇的：误差项，从属关系，中心点\n",
    "        \n",
    "        # 1/4        分裂的母簇更新之前保存历史记录      \n",
    "        disCenterIDs.append(needToSplit)\n",
    "        disCentroids.append(currentCentroids[needToSplit])\n",
    "        disErrorSum.append(ClusterErrorSum[needToSplit])\n",
    "        disErrorDelta.append(ErrorDelta[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        dissplitedError.append(splitedError[needToSplit])#按：其更新在新簇二分割聚类生成母簇时进行\n",
    "        \n",
    "        #2/4 误差项更新   注意区分使用和生成（更新）\n",
    "        #检查，已做掉的：\n",
    "        #ErrorDelta（确定分裂母簇时使用）\n",
    "        #splitedError、subClusterErrorSum 各子簇的误差平方和  新簇二分支形成母簇时使用，生成则在母簇分裂时\n",
    "        print('newClusterErrorSum[0]=',newClusterErrorSum[0])#测得 newClusterErrorSum[0]= [32.601242864951153]\n",
    "        ClusterErrorSum[needToSplit]=newClusterErrorSum[0]\n",
    "        ClusterErrorSum.append(newClusterErrorSum[1])        \n",
    "        #以下的要加上\n",
    "        splitedError[needToSplit]=[]\n",
    "        splitedError.append([])\n",
    "        subClusterErrorSum[needToSplit]=[]\n",
    "        subClusterErrorSum.append([]) \n",
    "        ErrorDelta[needToSplit]=[]\n",
    "        ErrorDelta.append([]) \n",
    "        \n",
    "        \n",
    "        \n",
    "        #3/4 从属关系更新    包括本簇的和分裂的子簇的\n",
    "        #本簇的从属关系更新\n",
    "        # 刷新点分配结果    #按：所属簇号  即从属关系更新\n",
    "        clusterAssment[np.nonzero(\n",
    "            clusterAssment[:, 0].A == needToSplit\n",
    "        )[0], :] = newClusterAssment  \n",
    "        print('np.unique(newClusterAssment[:, 0].A)=',np.unique(newClusterAssment[:, 0].A))\n",
    "        print('np.unique(clusterAssment[:, 0].A)=',np.unique(clusterAssment[:, 0].A ))\n",
    "        #按：原簇簇号为needToSplit的样本被新的二分簇族（注意：是族）\n",
    "        #                                             newClusterAss取代\n",
    "        #簇号不变  \n",
    "        #按：discenter表示被分裂的一代代母簇\n",
    "        #存储有：中心点，含有的误差平方和，母子分支的误差平方和的降低量\n",
    "        #子簇的从属关系更新\n",
    "        subClusterAss[needToSplit]=[]  #不能是[[]]，否则出错\n",
    "        subClusterAss.extend([[]])\n",
    "        \n",
    "        #4/4 中心点更新,包括本簇中心点更新currentCentroids和子簇中心点更新subClusterCentroids（重点：不能忽视）\n",
    "        #本簇中心点更新currentCentroids\n",
    "#         print('currentCentroids[needToSplit]=',currentCentroids[needToSplit])\n",
    "         # 被划分的簇需要更新\n",
    "        currentCentroids[needToSplit] = newCentroids[0]#.tolist()[0]#加了.tolist()[0]\n",
    "        # 加入新的划分后的簇\n",
    "        print('newCentroids[1]=',newCentroids[1]) #按：newCentroids[1]是单坐标点的列表[[单坐标点]]\n",
    "        #newCentroids[1]= [[-3.38237045 -2.9473363 ]]  #返回一单行的矩阵[[]]  #重点关注，矩阵而非列表\n",
    "#         currentCentroids.extend(newCentroids[1])#.tolist()[0])#加了.tolist()[0] #按：注意append和extend差别\n",
    "        currentCentroids.append(newCentroids[1])#.tolist()[0]\n",
    "        print('currentCentroids[-1]',currentCentroids[-1])\n",
    "        print('currentCentroids[-1][0]',currentCentroids[-1][0])\n",
    "        #子簇中心点更新subClusterCentroids\n",
    "        subClusterCentroids[needToSplit]=[]\n",
    "#         subClusterCentroids.extend([])  #按：考察功底的时刻\n",
    "#         subClusterCentroids.extend([])    #按：等于什么也没干\n",
    "        subClusterCentroids.extend([[]])  #按：增加了空位，即插入了[]，该序号i是可以用[i]append()来补充元素的\n",
    "#         subClusterCentroids.append([[]])  #按：增加了元素[[]]，插入的是空元素的单元素表\n",
    "        print('subClusterCentroids=',subClusterCentroids)\n",
    "      \n",
    "  \n",
    "        #按：一对分裂的子簇变成一对新生簇，内部二分割变成待选分裂的母簇\n",
    "        Indexes_of_newClusterCentroids_In_currentCentroids=[needToSplit,len(currentCentroids)-1]\n",
    "        print('Indexes_of_newClusterCentroids_In_currentCentroids=',Indexes_of_newClusterCentroids_In_currentCentroids)    \n",
    "        print('currentCentroids=',currentCentroids)\n",
    "        print('#####################################################################################')\n",
    "\n",
    "    #不堆叠，k类不会分开展示。位置放在最后return前更新更适宜  注意与return并头\n",
    "    currentCentroids=np.vstack(currentCentroids)\n",
    "    return np.mat(currentCentroids), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "475px",
    "left": "0px",
    "right": "auto",
    "top": "105px",
    "width": "301px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
